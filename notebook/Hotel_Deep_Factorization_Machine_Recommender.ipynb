{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smaller-darwin",
   "metadata": {},
   "source": [
    "# Expedia Hotel Recommender System- DeepFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-dominant",
   "metadata": {},
   "source": [
    "## Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "simple-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deepctr.layers.core import PredictionLayer, DNN\n",
    "from deepctr.layers.utils import add_func\n",
    "\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat,get_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-testimony",
   "metadata": {},
   "source": [
    "# Reading and Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "banner-drilling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 24)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"..\\data\\\\train.csv\", sep=',', nrows=150000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "statistical-internship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>is_booking</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-11 07:46:59</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11 08:22:12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time  site_name  posa_continent  user_location_country  \\\n",
       "0  2014-08-11 07:46:59          2               3                     66   \n",
       "1  2014-08-11 08:22:12          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   348               48862                  2234.2641   \n",
       "1                   348               48862                  2234.2641   \n",
       "\n",
       "   user_id  is_mobile  is_package  ...  srch_children_cnt srch_rm_cnt  \\\n",
       "0       12          0           1  ...                  0           1   \n",
       "1       12          0           1  ...                  0           1   \n",
       "\n",
       "  srch_destination_id  srch_destination_type_id  is_booking  cnt  \\\n",
       "0                8250                         1           0    3   \n",
       "1                8250                         1           1    1   \n",
       "\n",
       "   hotel_continent  hotel_country  hotel_market  hotel_cluster  \n",
       "0                2             50           628              1  \n",
       "1                2             50           628              1  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "skilled-halifax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   date_time                  150000 non-null  object \n",
      " 1   site_name                  150000 non-null  int64  \n",
      " 2   posa_continent             150000 non-null  int64  \n",
      " 3   user_location_country      150000 non-null  int64  \n",
      " 4   user_location_region       150000 non-null  int64  \n",
      " 5   user_location_city         150000 non-null  int64  \n",
      " 6   orig_destination_distance  97558 non-null   float64\n",
      " 7   user_id                    150000 non-null  int64  \n",
      " 8   is_mobile                  150000 non-null  int64  \n",
      " 9   is_package                 150000 non-null  int64  \n",
      " 10  channel                    150000 non-null  int64  \n",
      " 11  srch_ci                    149875 non-null  object \n",
      " 12  srch_co                    149875 non-null  object \n",
      " 13  srch_adults_cnt            150000 non-null  int64  \n",
      " 14  srch_children_cnt          150000 non-null  int64  \n",
      " 15  srch_rm_cnt                150000 non-null  int64  \n",
      " 16  srch_destination_id        150000 non-null  int64  \n",
      " 17  srch_destination_type_id   150000 non-null  int64  \n",
      " 18  is_booking                 150000 non-null  int64  \n",
      " 19  cnt                        150000 non-null  int64  \n",
      " 20  hotel_continent            150000 non-null  int64  \n",
      " 21  hotel_country              150000 non-null  int64  \n",
      " 22  hotel_market               150000 non-null  int64  \n",
      " 23  hotel_cluster              150000 non-null  int64  \n",
      " 24  click_month                150000 non-null  int64  \n",
      "dtypes: float64(1), int64(21), object(3)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "healthy-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['click_month'] = pd.DatetimeIndex(df['date_time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "nuclear-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(['date_time'],axis=1)\n",
    "df= df.drop(['orig_destination_distance'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "specialized-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract month from date_time\n",
    "df['checkin_month'] = pd.DatetimeIndex(df['srch_ci']).month\n",
    "df['checkout_month'] = pd.DatetimeIndex(df['srch_co']).month\n",
    "df['click_month'] = pd.DatetimeIndex(df['date_time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "white-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(['date_time'],axis=1)\n",
    "df= df.drop(['srch_ci'],axis=1)\n",
    "df= df.drop(['srch_co'],axis=1)\n",
    "df= df.drop(['orig_destination_distance'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "opposed-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df = df.rename(columns={'hotel_cluster': 'item_id', 'is_booking': 'rating'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-matrix",
   "metadata": {},
   "source": [
    "### Sparse Features/ Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "flying-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categ_sparse \n",
    "sparse_features = ['site_name','posa_continent','user_location_country','user_location_region','user_location_city',\n",
    "             'user_id','is_mobile','is_package','channel','click_month','checkin_month','checkout_month',\n",
    "            'srch_adults_cnt','srch_children_cnt','srch_rm_cnt','srch_destination_id','hotel_continent',\n",
    "               'hotel_country','cnt','click_month', 'checkin_month','checkout_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dated-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categ_sparse \n",
    "sparse_features = ['site_name','posa_continent','user_location_country','user_location_region','user_location_city',\n",
    "             'user_id','is_mobile','is_package','channel','click_month','srch_ci','srch_co',\n",
    "            'srch_adults_cnt','srch_children_cnt','srch_rm_cnt','srch_destination_id','hotel_continent',\n",
    "               'hotel_country','cnt','click_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-clothing",
   "metadata": {},
   "source": [
    "### Dense Features/ Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "inner-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features = ['hotel_market']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-public",
   "metadata": {},
   "source": [
    "### Target Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "honest-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-lancaster",
   "metadata": {},
   "source": [
    "## Simple preprocessing\n",
    "\n",
    "Usually we have two methods to encode the sparse categorical feature for embedding\n",
    "\n",
    "**Label Encoding: map the features to integer value from 0 ~ len(#unique) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cutting-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for sparse features,and normalization for dense numerical features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    df[feat] = lbe.fit_transform(df[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-prince",
   "metadata": {},
   "source": [
    "### Here we use normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "premium-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "df[dense_features] = mms.fit_transform(df[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-transcript",
   "metadata": {},
   "source": [
    "## Generate feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-warren",
   "metadata": {},
   "source": [
    "For sparse features, we transform them into dense vectors by embedding techniques. For dense numerical features, we concatenate them to the input tensors of fully connected layer.\n",
    "\n",
    "**Label Encoding and Generate feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "essential-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=df[feat].nunique(),embedding_dim=4)\n",
    "                       for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
    "                      for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-notion",
   "metadata": {},
   "source": [
    "## Generate the training samples and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "subjective-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-british",
   "metadata": {},
   "source": [
    "## Define Model and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "abstract-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_feature_columns,dnn_feature_columns,task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "aquatic-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 - 4s - loss: 0.2711 - binary_crossentropy: 0.2706 - val_loss: 0.2428 - val_binary_crossentropy: 0.2418\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.2214 - binary_crossentropy: 0.2199 - val_loss: 0.2533 - val_binary_crossentropy: 0.2512\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.2071 - binary_crossentropy: 0.2045 - val_loss: 0.2715 - val_binary_crossentropy: 0.2684\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.1976 - binary_crossentropy: 0.1942 - val_loss: 0.2788 - val_binary_crossentropy: 0.2750\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.1905 - binary_crossentropy: 0.1865 - val_loss: 0.2993 - val_binary_crossentropy: 0.2950\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.1841 - binary_crossentropy: 0.1795 - val_loss: 0.3224 - val_binary_crossentropy: 0.3175\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.1776 - binary_crossentropy: 0.1726 - val_loss: 0.3396 - val_binary_crossentropy: 0.3344\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.1713 - binary_crossentropy: 0.1661 - val_loss: 0.3545 - val_binary_crossentropy: 0.3491\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.1648 - binary_crossentropy: 0.1593 - val_loss: 0.3873 - val_binary_crossentropy: 0.3816\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.1589 - binary_crossentropy: 0.1531 - val_loss: 0.4129 - val_binary_crossentropy: 0.4070\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "searching-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "pred_result = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "straight-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t0.300000\n",
      "MAE:\t0.150000\n",
      "MSE:\t0.090000\n",
      "AUC:\t0.710000\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test[target].values, pred_result)\n",
    "\n",
    "print(\"RMSE:\\t%f\" % np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\"MAE:\\t%f\" % np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE:\\t%f\" % np.round(mean_squared_error(test[target].values, pred_result),2),\"AUC:\\t%f\" % np.round(auc,2),sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-entertainment",
   "metadata": {},
   "source": [
    "## Let's Experiments on Hyper-parameters tuning and see their effect on model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-vancouver",
   "metadata": {},
   "source": [
    "### Instantiates the DeepFM Network architecture.\n",
    "\n",
    "#### Parameters:\t\n",
    "\n",
    "linear_feature_columns â€“ An iterable containing all the features used by linear part of the model.\n",
    "\n",
    "dnn_feature_columns â€“ An iterable containing all the features used by deep part of the model.\n",
    "\n",
    "fm_group â€“ list, group_name of features that will be used to do feature interactions.\n",
    "\n",
    "dnn_hidden_units â€“ list,list of positive integer or empty list, the layer number and units in each layer of DNN\n",
    "\n",
    "l2_reg_linear â€“ float. L2 regularizer strength applied to linear part\n",
    "\n",
    "l2_reg_embedding â€“ float. L2 regularizer strength applied to embedding vector\n",
    "\n",
    "l2_reg_dnn â€“ float. L2 regularizer strength applied to DNN\n",
    "\n",
    "seed â€“ integer ,to use as random seed.\n",
    "\n",
    "dnn_dropout â€“ float in [0,1), the probability we will drop out a given DNN coordinate.\n",
    "\n",
    "dnn_activation â€“ Activation function to use in DNN\n",
    "\n",
    "dnn_use_bn â€“ bool. Whether use BatchNormalization before activation or not in DNN\n",
    "\n",
    "task â€“ str, \"binary\" for binary logloss or \"regression\" for regression loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-grocery",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters with GridSearchCV\n",
    "\n",
    "Grid search, which is an optimization scheme trying all possible combinations of specified hyperparameter choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "reasonable-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'dnn_hidden_units' : [(1,1),(2,2),(4,4),(27,27),(128,128),(256,256)],\n",
    "              'dnn_use_bn':[True,False],\n",
    "              'l2_reg_linear':[1e-5,1e-3,1e-1,1,10],\n",
    "              'l2_reg_embedding':[1e-7,1e-5,1e-3,1e-1,1],\n",
    "              'l2_reg_dnn':[0,0.2,2,4],\n",
    "              'dnn_dropout':[0, 0.1, 0.3, 0.7, 0.9,0.11]\n",
    "             }\n",
    "result = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-transformation",
   "metadata": {},
   "source": [
    "### dnn_hidden_units â€“ list,list of positive integer or empty list, the layer number and units in each layer of DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "sound-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0883 - mse: 0.0881 - val_loss: 0.0742 - val_mse: 0.0737\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0700 - mse: 0.0692 - val_loss: 0.0735 - val_mse: 0.0725\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0678 - mse: 0.0665 - val_loss: 0.0739 - val_mse: 0.0724\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0665 - mse: 0.0647 - val_loss: 0.0745 - val_mse: 0.0726\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0656 - mse: 0.0635 - val_loss: 0.0756 - val_mse: 0.0734\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0648 - mse: 0.0624 - val_loss: 0.0764 - val_mse: 0.0740\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0643 - mse: 0.0617 - val_loss: 0.0767 - val_mse: 0.0740\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0637 - mse: 0.0610 - val_loss: 0.0793 - val_mse: 0.0765\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0633 - mse: 0.0603 - val_loss: 0.0784 - val_mse: 0.0754\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0629 - mse: 0.0599 - val_loss: 0.0801 - val_mse: 0.0770\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0840 - mse: 0.0838 - val_loss: 0.0733 - val_mse: 0.0728\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0686 - mse: 0.0678 - val_loss: 0.0732 - val_mse: 0.0721\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0660 - mse: 0.0646 - val_loss: 0.0746 - val_mse: 0.0730\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0642 - mse: 0.0625 - val_loss: 0.0767 - val_mse: 0.0748\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0629 - mse: 0.0609 - val_loss: 0.0783 - val_mse: 0.0763\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0619 - mse: 0.0597 - val_loss: 0.0795 - val_mse: 0.0773\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0610 - mse: 0.0588 - val_loss: 0.0819 - val_mse: 0.0797\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0603 - mse: 0.0580 - val_loss: 0.0818 - val_mse: 0.0796\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0598 - mse: 0.0574 - val_loss: 0.0829 - val_mse: 0.0806\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0594 - mse: 0.0570 - val_loss: 0.0845 - val_mse: 0.0822\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0879 - mse: 0.0877 - val_loss: 0.0741 - val_mse: 0.0736\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0698 - mse: 0.0690 - val_loss: 0.0734 - val_mse: 0.0724\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0677 - mse: 0.0663 - val_loss: 0.0738 - val_mse: 0.0723\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0664 - mse: 0.0646 - val_loss: 0.0754 - val_mse: 0.0735\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0654 - mse: 0.0632 - val_loss: 0.0755 - val_mse: 0.0733\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0646 - mse: 0.0622 - val_loss: 0.0769 - val_mse: 0.0744\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0639 - mse: 0.0613 - val_loss: 0.0769 - val_mse: 0.0742\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0633 - mse: 0.0605 - val_loss: 0.0779 - val_mse: 0.0750\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0627 - mse: 0.0597 - val_loss: 0.0797 - val_mse: 0.0767\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0620 - mse: 0.0589 - val_loss: 0.0805 - val_mse: 0.0774\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0818 - mse: 0.0816 - val_loss: 0.0723 - val_mse: 0.0717\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0670 - mse: 0.0661 - val_loss: 0.0729 - val_mse: 0.0718\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0640 - mse: 0.0628 - val_loss: 0.0749 - val_mse: 0.0736\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0623 - mse: 0.0608 - val_loss: 0.0772 - val_mse: 0.0757\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0609 - mse: 0.0593 - val_loss: 0.0785 - val_mse: 0.0768\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0599 - mse: 0.0582 - val_loss: 0.0793 - val_mse: 0.0775\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0591 - mse: 0.0573 - val_loss: 0.0828 - val_mse: 0.0809\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0585 - mse: 0.0566 - val_loss: 0.0811 - val_mse: 0.0792\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0579 - mse: 0.0560 - val_loss: 0.0831 - val_mse: 0.0811\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0574 - mse: 0.0554 - val_loss: 0.0855 - val_mse: 0.0835\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0768 - mse: 0.0766 - val_loss: 0.0718 - val_mse: 0.0713\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0662 - mse: 0.0654 - val_loss: 0.0732 - val_mse: 0.0722\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.0634 - mse: 0.0624 - val_loss: 0.0755 - val_mse: 0.0742\n",
      "Epoch 4/10\n",
      "375/375 - 3s - loss: 0.0617 - mse: 0.0604 - val_loss: 0.0773 - val_mse: 0.0759\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0603 - mse: 0.0588 - val_loss: 0.0794 - val_mse: 0.0779\n",
      "Epoch 6/10\n",
      "375/375 - 3s - loss: 0.0593 - mse: 0.0577 - val_loss: 0.0796 - val_mse: 0.0779\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0584 - mse: 0.0567 - val_loss: 0.0835 - val_mse: 0.0818\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0575 - mse: 0.0557 - val_loss: 0.0852 - val_mse: 0.0834\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0565 - mse: 0.0546 - val_loss: 0.0867 - val_mse: 0.0848\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0557 - mse: 0.0537 - val_loss: 0.0878 - val_mse: 0.0858\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 5s - loss: 0.0755 - mse: 0.0753 - val_loss: 0.0717 - val_mse: 0.0712\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0661 - mse: 0.0654 - val_loss: 0.0731 - val_mse: 0.0722\n",
      "Epoch 3/10\n",
      "375/375 - 4s - loss: 0.0635 - mse: 0.0624 - val_loss: 0.0751 - val_mse: 0.0739\n",
      "Epoch 4/10\n",
      "375/375 - 3s - loss: 0.0618 - mse: 0.0605 - val_loss: 0.0769 - val_mse: 0.0755\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.0604 - mse: 0.0589 - val_loss: 0.0789 - val_mse: 0.0773\n",
      "Epoch 6/10\n",
      "375/375 - 4s - loss: 0.0593 - mse: 0.0577 - val_loss: 0.0806 - val_mse: 0.0789\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0582 - mse: 0.0565 - val_loss: 0.0830 - val_mse: 0.0812\n",
      "Epoch 8/10\n",
      "375/375 - 4s - loss: 0.0573 - mse: 0.0555 - val_loss: 0.0854 - val_mse: 0.0835\n",
      "Epoch 9/10\n",
      "375/375 - 4s - loss: 0.0564 - mse: 0.0545 - val_loss: 0.0873 - val_mse: 0.0854\n",
      "Epoch 10/10\n",
      "375/375 - 4s - loss: 0.0556 - mse: 0.0536 - val_loss: 0.0873 - val_mse: 0.0853\n"
     ]
    }
   ],
   "source": [
    "dnn_hidden_units_layer = {}\n",
    "for x in param_grid['dnn_hidden_units']:\n",
    "    model = DeepFM(linear_feature_columns,dnn_feature_columns,fm_group=['default_group'], dnn_hidden_units=x, \n",
    "              seed=1024,task='binary')\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    dnn_hidden_units_layer[x]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),2),\n",
    "      \"AUC\" : np.round(auc,2)}\n",
    "result['dnn_hidden_units']=dnn_hidden_units_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "unable-underground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): {'RMSE': 0.28, 'MAE': 0.15, 'MSE': 0.08, 'AUC': 0.77},\n",
       " (2, 2): {'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.75},\n",
       " (4, 4): {'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.77},\n",
       " (27, 27): {'RMSE': 0.29, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.75},\n",
       " (128, 128): {'RMSE': 0.29, 'MAE': 0.13, 'MSE': 0.08, 'AUC': 0.74},\n",
       " (256, 256): {'RMSE': 0.29, 'MAE': 0.13, 'MSE': 0.08, 'AUC': 0.75}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_hidden_units_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "exact-third",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.77}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_hidden_units_layer[(4,4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-revelation",
   "metadata": {},
   "source": [
    "### dnn_use_bn â€“ bool. Whether use BatchNormalization before activation or not in DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "computational-european",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1048 - mse: 0.1047 - val_loss: 0.0770 - val_mse: 0.0768\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0682 - mse: 0.0680 - val_loss: 0.0745 - val_mse: 0.0741\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0647 - mse: 0.0642 - val_loss: 0.0761 - val_mse: 0.0755\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0621 - mse: 0.0615 - val_loss: 0.0798 - val_mse: 0.0790\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0602 - mse: 0.0594 - val_loss: 0.0811 - val_mse: 0.0802\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0588 - mse: 0.0578 - val_loss: 0.0838 - val_mse: 0.0827\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0578 - mse: 0.0567 - val_loss: 0.0838 - val_mse: 0.0826\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0568 - mse: 0.0555 - val_loss: 0.0887 - val_mse: 0.0874\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0562 - mse: 0.0548 - val_loss: 0.0851 - val_mse: 0.0837\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0557 - mse: 0.0542 - val_loss: 0.0893 - val_mse: 0.0878\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0851 - mse: 0.0849 - val_loss: 0.0739 - val_mse: 0.0734\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0692 - mse: 0.0684 - val_loss: 0.0730 - val_mse: 0.0719\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0667 - mse: 0.0653 - val_loss: 0.0741 - val_mse: 0.0726\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0649 - mse: 0.0632 - val_loss: 0.0756 - val_mse: 0.0738\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0635 - mse: 0.0615 - val_loss: 0.0775 - val_mse: 0.0754\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0624 - mse: 0.0602 - val_loss: 0.0796 - val_mse: 0.0774\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0614 - mse: 0.0591 - val_loss: 0.0800 - val_mse: 0.0777\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0607 - mse: 0.0583 - val_loss: 0.0805 - val_mse: 0.0781\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0600 - mse: 0.0576 - val_loss: 0.0816 - val_mse: 0.0792\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0594 - mse: 0.0569 - val_loss: 0.0827 - val_mse: 0.0802\n"
     ]
    }
   ],
   "source": [
    "dnn_use_bn_dict = {}\n",
    "for x in param_grid['dnn_use_bn']:\n",
    "    model= DeepFM(linear_feature_columns,dnn_feature_columns,fm_group=['default_group'],dnn_hidden_units=(4,4), \n",
    "              seed=1024,task='binary',dnn_use_bn=x)\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    dnn_use_bn_dict[x]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),2),\n",
    "      \"AUC\" : np.round(auc,3)}\n",
    "result['dnn_use_bn_dict']=dnn_use_bn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "relevant-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True: {'RMSE': 0.29, 'MAE': 0.16, 'MSE': 0.09, 'AUC': 0.741},\n",
       " False: {'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.758}}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_use_bn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "seeing-liver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.758}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_use_bn_dict[False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-finnish",
   "metadata": {},
   "source": [
    "### l2_reg_linear â€“ float. L2 regularizer strength applied to linear part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "yellow-impact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 - 3s - loss: 0.0857 - mse: 0.0855 - val_loss: 0.0735 - val_mse: 0.0730\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0688 - mse: 0.0680 - val_loss: 0.0728 - val_mse: 0.0718\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0661 - mse: 0.0648 - val_loss: 0.0740 - val_mse: 0.0726\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0641 - mse: 0.0625 - val_loss: 0.0760 - val_mse: 0.0743\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0626 - mse: 0.0607 - val_loss: 0.0775 - val_mse: 0.0756\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0613 - mse: 0.0593 - val_loss: 0.0799 - val_mse: 0.0778\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0603 - mse: 0.0582 - val_loss: 0.0809 - val_mse: 0.0787\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0595 - mse: 0.0573 - val_loss: 0.0835 - val_mse: 0.0813\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0589 - mse: 0.0566 - val_loss: 0.0852 - val_mse: 0.0829\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0582 - mse: 0.0559 - val_loss: 0.0844 - val_mse: 0.0820\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0842 - mse: 0.0832 - val_loss: 0.0736 - val_mse: 0.0725\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0688 - mse: 0.0675 - val_loss: 0.0734 - val_mse: 0.0720\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0658 - mse: 0.0642 - val_loss: 0.0757 - val_mse: 0.0740\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0638 - mse: 0.0619 - val_loss: 0.0769 - val_mse: 0.0750\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0622 - mse: 0.0602 - val_loss: 0.0797 - val_mse: 0.0777\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0611 - mse: 0.0590 - val_loss: 0.0801 - val_mse: 0.0780\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0602 - mse: 0.0581 - val_loss: 0.0816 - val_mse: 0.0794\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0594 - mse: 0.0572 - val_loss: 0.0827 - val_mse: 0.0805\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0587 - mse: 0.0565 - val_loss: 0.0844 - val_mse: 0.0822\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0583 - mse: 0.0560 - val_loss: 0.0847 - val_mse: 0.0824\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0921 - mse: 0.0851 - val_loss: 0.0735 - val_mse: 0.0724\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0685 - mse: 0.0673 - val_loss: 0.0730 - val_mse: 0.0717\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0656 - mse: 0.0641 - val_loss: 0.0750 - val_mse: 0.0733\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0638 - mse: 0.0620 - val_loss: 0.0769 - val_mse: 0.0749\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0625 - mse: 0.0605 - val_loss: 0.0783 - val_mse: 0.0762\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0614 - mse: 0.0592 - val_loss: 0.0811 - val_mse: 0.0789\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0606 - mse: 0.0583 - val_loss: 0.0811 - val_mse: 0.0788\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0599 - mse: 0.0575 - val_loss: 0.0828 - val_mse: 0.0804\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0593 - mse: 0.0569 - val_loss: 0.0837 - val_mse: 0.0813\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0588 - mse: 0.0564 - val_loss: 0.0840 - val_mse: 0.0815\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 5s - loss: 0.1321 - mse: 0.0914 - val_loss: 0.0785 - val_mse: 0.0741\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0707 - mse: 0.0691 - val_loss: 0.0734 - val_mse: 0.0723\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0667 - mse: 0.0653 - val_loss: 0.0742 - val_mse: 0.0727\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0647 - mse: 0.0629 - val_loss: 0.0761 - val_mse: 0.0742\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0632 - mse: 0.0611 - val_loss: 0.0780 - val_mse: 0.0759\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0619 - mse: 0.0597 - val_loss: 0.0787 - val_mse: 0.0765\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0611 - mse: 0.0587 - val_loss: 0.0804 - val_mse: 0.0781\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0604 - mse: 0.0580 - val_loss: 0.0817 - val_mse: 0.0793\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0597 - mse: 0.0572 - val_loss: 0.0825 - val_mse: 0.0800\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0592 - mse: 0.0567 - val_loss: 0.0829 - val_mse: 0.0804\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.4656 - mse: 0.0944 - val_loss: 0.1169 - val_mse: 0.0736\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0779 - mse: 0.0683 - val_loss: 0.0731 - val_mse: 0.0718\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0660 - mse: 0.0646 - val_loss: 0.0752 - val_mse: 0.0736\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0641 - mse: 0.0623 - val_loss: 0.0763 - val_mse: 0.0745\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0626 - mse: 0.0606 - val_loss: 0.0777 - val_mse: 0.0757\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0614 - mse: 0.0593 - val_loss: 0.0799 - val_mse: 0.0777\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0606 - mse: 0.0583 - val_loss: 0.0808 - val_mse: 0.0785\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0599 - mse: 0.0575 - val_loss: 0.0816 - val_mse: 0.0793\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0592 - mse: 0.0568 - val_loss: 0.0833 - val_mse: 0.0808\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0588 - mse: 0.0563 - val_loss: 0.0834 - val_mse: 0.0809\n"
     ]
    }
   ],
   "source": [
    "l2_reg_linear_dict={}\n",
    "for x in param_grid['l2_reg_linear']:\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(4,4), l2_reg_linear=x,\n",
    "            fm_group=['default_group'], dnn_use_bn=False,\n",
    "                   seed=1024,task='binary')\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    \n",
    "    l2_reg_linear_dict[x]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),2),\n",
    "      \"AUC\" : np.round(auc,2)}\n",
    "    \n",
    "result['l2_reg_linear']=l2_reg_linear_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "incredible-production",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-05: {'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.76},\n",
       " 0.001: {'RMSE': 0.29, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.75},\n",
       " 0.1: {'RMSE': 0.28, 'MAE': 0.13, 'MSE': 0.08, 'AUC': 0.75},\n",
       " 1: {'RMSE': 0.28, 'MAE': 0.13, 'MSE': 0.08, 'AUC': 0.76},\n",
       " 10: {'RMSE': 0.28, 'MAE': 0.13, 'MSE': 0.08, 'AUC': 0.75}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_linear_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "recorded-casting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.76}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_linear_dict[1e-05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-antenna",
   "metadata": {},
   "source": [
    "### l2_reg_embedding â€“ float. L2 regularizer strength applied to embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "determined-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0840 - mse: 0.0840 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0671 - mse: 0.0670 - val_loss: 0.0725 - val_mse: 0.0724\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0631 - mse: 0.0629 - val_loss: 0.0751 - val_mse: 0.0749\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0606 - mse: 0.0604 - val_loss: 0.0764 - val_mse: 0.0762\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0587 - mse: 0.0585 - val_loss: 0.0787 - val_mse: 0.0785\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0574 - mse: 0.0572 - val_loss: 0.0797 - val_mse: 0.0795\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0564 - mse: 0.0562 - val_loss: 0.0813 - val_mse: 0.0811\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0555 - mse: 0.0553 - val_loss: 0.0828 - val_mse: 0.0826\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0548 - mse: 0.0546 - val_loss: 0.0837 - val_mse: 0.0835\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0542 - mse: 0.0540 - val_loss: 0.0844 - val_mse: 0.0842\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0874 - mse: 0.0872 - val_loss: 0.0748 - val_mse: 0.0744\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0695 - mse: 0.0687 - val_loss: 0.0728 - val_mse: 0.0718\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0663 - mse: 0.0650 - val_loss: 0.0741 - val_mse: 0.0727\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0644 - mse: 0.0628 - val_loss: 0.0764 - val_mse: 0.0747\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0629 - mse: 0.0611 - val_loss: 0.0780 - val_mse: 0.0762\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0617 - mse: 0.0598 - val_loss: 0.0789 - val_mse: 0.0769\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0606 - mse: 0.0586 - val_loss: 0.0810 - val_mse: 0.0789\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0599 - mse: 0.0577 - val_loss: 0.0823 - val_mse: 0.0801\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0592 - mse: 0.0570 - val_loss: 0.0820 - val_mse: 0.0798\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0586 - mse: 0.0563 - val_loss: 0.0837 - val_mse: 0.0814\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0877 - mse: 0.0864 - val_loss: 0.0770 - val_mse: 0.0754\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0736 - mse: 0.0716 - val_loss: 0.0756 - val_mse: 0.0735\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0723 - mse: 0.0701 - val_loss: 0.0750 - val_mse: 0.0727\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0715 - mse: 0.0691 - val_loss: 0.0746 - val_mse: 0.0722\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0710 - mse: 0.0684 - val_loss: 0.0743 - val_mse: 0.0719\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0706 - mse: 0.0679 - val_loss: 0.0747 - val_mse: 0.0720\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0704 - mse: 0.0674 - val_loss: 0.0745 - val_mse: 0.0716\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0701 - mse: 0.0672 - val_loss: 0.0745 - val_mse: 0.0717\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0698 - mse: 0.0668 - val_loss: 0.0744 - val_mse: 0.0715\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0698 - mse: 0.0665 - val_loss: 0.0745 - val_mse: 0.0716\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0901 - mse: 0.0899 - val_loss: 0.0776 - val_mse: 0.0774\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0743 - mse: 0.0741 - val_loss: 0.0764 - val_mse: 0.0762\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0729 - mse: 0.0727 - val_loss: 0.0754 - val_mse: 0.0751\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0717 - mse: 0.0713 - val_loss: 0.0746 - val_mse: 0.0741\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0708 - mse: 0.0702 - val_loss: 0.0741 - val_mse: 0.0735\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0701 - mse: 0.0693 - val_loss: 0.0738 - val_mse: 0.0730\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0696 - mse: 0.0686 - val_loss: 0.0737 - val_mse: 0.0727\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0692 - mse: 0.0681 - val_loss: 0.0736 - val_mse: 0.0724\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0689 - mse: 0.0677 - val_loss: 0.0736 - val_mse: 0.0723\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0687 - mse: 0.0674 - val_loss: 0.0736 - val_mse: 0.0722\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0904 - mse: 0.0897 - val_loss: 0.0776 - val_mse: 0.0775\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0743 - mse: 0.0742 - val_loss: 0.0764 - val_mse: 0.0763\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0729 - mse: 0.0727 - val_loss: 0.0754 - val_mse: 0.0751\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0717 - mse: 0.0713 - val_loss: 0.0746 - val_mse: 0.0741\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0708 - mse: 0.0702 - val_loss: 0.0742 - val_mse: 0.0735\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0701 - mse: 0.0693 - val_loss: 0.0739 - val_mse: 0.0730\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0696 - mse: 0.0687 - val_loss: 0.0737 - val_mse: 0.0727\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0693 - mse: 0.0681 - val_loss: 0.0737 - val_mse: 0.0725\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0690 - mse: 0.0677 - val_loss: 0.0736 - val_mse: 0.0723\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0688 - mse: 0.0674 - val_loss: 0.0737 - val_mse: 0.0722\n"
     ]
    }
   ],
   "source": [
    "l2_reg_embedding_layer={}\n",
    "for x in param_grid['l2_reg_embedding']:\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(4,4), l2_reg_linear=1e-05,l2_reg_embedding=x, seed=1024, task='binary',\n",
    "               dnn_use_bn=False,fm_group=['default_group'])\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    l2_reg_embedding_layer[x]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),2),\n",
    "      \"AUC\" : np.round(auc,2)}\n",
    "result['l2_reg_embedding']=l2_reg_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "common-louisville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-07: {'RMSE': 0.29, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.74},\n",
       " 1e-05: {'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.75},\n",
       " 0.001: {'RMSE': 0.26, 'MAE': 0.15, 'MSE': 0.07, 'AUC': 0.78},\n",
       " 0.1: {'RMSE': 0.27, 'MAE': 0.16, 'MSE': 0.07, 'AUC': 0.77},\n",
       " 1: {'RMSE': 0.27, 'MAE': 0.16, 'MSE': 0.07, 'AUC': 0.77}}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "disturbed-greece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.26, 'MAE': 0.15, 'MSE': 0.07, 'AUC': 0.78}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_embedding_layer[.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-topic",
   "metadata": {},
   "source": [
    "### l2_reg_dnn: float. L2 regularizer strength applied to DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "complimentary-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0876 - mse: 0.0862 - val_loss: 0.0770 - val_mse: 0.0753\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0736 - mse: 0.0718 - val_loss: 0.0755 - val_mse: 0.0738\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0722 - mse: 0.0703 - val_loss: 0.0750 - val_mse: 0.0730\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0715 - mse: 0.0693 - val_loss: 0.0747 - val_mse: 0.0724\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0710 - mse: 0.0686 - val_loss: 0.0746 - val_mse: 0.0721\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0706 - mse: 0.0680 - val_loss: 0.0744 - val_mse: 0.0719\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0703 - mse: 0.0675 - val_loss: 0.0744 - val_mse: 0.0718\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0701 - mse: 0.0672 - val_loss: 0.0744 - val_mse: 0.0716\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0699 - mse: 0.0669 - val_loss: 0.0744 - val_mse: 0.0717\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0696 - mse: 0.0666 - val_loss: 0.0743 - val_mse: 0.0715\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.8951 - mse: 0.0874 - val_loss: 0.3643 - val_mse: 0.0768\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.2428 - mse: 0.0729 - val_loss: 0.1647 - val_mse: 0.0748\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.1226 - mse: 0.0713 - val_loss: 0.0985 - val_mse: 0.0739\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0835 - mse: 0.0703 - val_loss: 0.0794 - val_mse: 0.0734\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0731 - mse: 0.0696 - val_loss: 0.0752 - val_mse: 0.0730\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0709 - mse: 0.0690 - val_loss: 0.0745 - val_mse: 0.0727\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0703 - mse: 0.0685 - val_loss: 0.0746 - val_mse: 0.0726\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0700 - mse: 0.0681 - val_loss: 0.0743 - val_mse: 0.0724\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0697 - mse: 0.0678 - val_loss: 0.0742 - val_mse: 0.0723\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0694 - mse: 0.0675 - val_loss: 0.0741 - val_mse: 0.0722\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 8.6727 - mse: 0.0876 - val_loss: 2.9111 - val_mse: 0.0769\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 1.6790 - mse: 0.0729 - val_loss: 0.8833 - val_mse: 0.0747\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.5246 - mse: 0.0712 - val_loss: 0.2875 - val_mse: 0.0739\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.1823 - mse: 0.0702 - val_loss: 0.1202 - val_mse: 0.0733\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0923 - mse: 0.0695 - val_loss: 0.0816 - val_mse: 0.0729\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0735 - mse: 0.0689 - val_loss: 0.0751 - val_mse: 0.0727\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0704 - mse: 0.0684 - val_loss: 0.0744 - val_mse: 0.0726\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0699 - mse: 0.0681 - val_loss: 0.0742 - val_mse: 0.0724\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0696 - mse: 0.0677 - val_loss: 0.0741 - val_mse: 0.0722\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0694 - mse: 0.0675 - val_loss: 0.0741 - val_mse: 0.0722\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 15.9593 - mse: 0.0881 - val_loss: 4.4172 - val_mse: 0.0763\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 2.1550 - mse: 0.0725 - val_loss: 0.8574 - val_mse: 0.0746\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.4356 - mse: 0.0711 - val_loss: 0.1993 - val_mse: 0.0737\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.1257 - mse: 0.0702 - val_loss: 0.0906 - val_mse: 0.0732\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0773 - mse: 0.0695 - val_loss: 0.0761 - val_mse: 0.0729\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0712 - mse: 0.0689 - val_loss: 0.0745 - val_mse: 0.0727\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0703 - mse: 0.0685 - val_loss: 0.0745 - val_mse: 0.0726\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0700 - mse: 0.0681 - val_loss: 0.0743 - val_mse: 0.0724\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0697 - mse: 0.0678 - val_loss: 0.0744 - val_mse: 0.0723\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0695 - mse: 0.0675 - val_loss: 0.0741 - val_mse: 0.0722\n"
     ]
    }
   ],
   "source": [
    "l2_reg_dnn_dict={}\n",
    "for x in param_grid['l2_reg_dnn']:\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(4, 4), l2_reg_linear=1e-05,\n",
    "            l2_reg_embedding=0.001, l2_reg_dnn=x, seed=1024,task='binary',dnn_use_bn=False,fm_group=['default_group'])\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    \n",
    "    l2_reg_dnn_dict[x]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),2),\n",
    "      \"AUC\" : np.round(auc,2)}\n",
    "result['l2_reg_dnn']=l2_reg_dnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "electoral-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'RMSE': 0.27, 'MAE': 0.14, 'MSE': 0.07, 'AUC': 0.78},\n",
       " 0.2: {'RMSE': 0.27, 'MAE': 0.15, 'MSE': 0.07, 'AUC': 0.77},\n",
       " 2: {'RMSE': 0.27, 'MAE': 0.15, 'MSE': 0.07, 'AUC': 0.77},\n",
       " 4: {'RMSE': 0.27, 'MAE': 0.15, 'MSE': 0.07, 'AUC': 0.77}}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_dnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "opened-celebrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.27, 'MAE': 0.14, 'MSE': 0.07, 'AUC': 0.78}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_dnn_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-render",
   "metadata": {},
   "source": [
    "### dnn_dropout â€“ float in [0,1), the probability we will drop out a given DNN coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "iraqi-tournament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0853 - mse: 0.0851 - val_loss: 0.0736 - val_mse: 0.0731\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0689 - mse: 0.0680 - val_loss: 0.0732 - val_mse: 0.0722\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0661 - mse: 0.0648 - val_loss: 0.0747 - val_mse: 0.0732\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0643 - mse: 0.0626 - val_loss: 0.0771 - val_mse: 0.0753\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0628 - mse: 0.0610 - val_loss: 0.0779 - val_mse: 0.0760\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0618 - mse: 0.0598 - val_loss: 0.0800 - val_mse: 0.0780\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0610 - mse: 0.0589 - val_loss: 0.0827 - val_mse: 0.0806\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0602 - mse: 0.0580 - val_loss: 0.0823 - val_mse: 0.0802\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0596 - mse: 0.0574 - val_loss: 0.0820 - val_mse: 0.0798\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0591 - mse: 0.0568 - val_loss: 0.0846 - val_mse: 0.0824\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0873 - mse: 0.0871 - val_loss: 0.0745 - val_mse: 0.0741\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0703 - mse: 0.0696 - val_loss: 0.0730 - val_mse: 0.0721\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0675 - mse: 0.0663 - val_loss: 0.0735 - val_mse: 0.0721\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0658 - mse: 0.0641 - val_loss: 0.0749 - val_mse: 0.0731\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0646 - mse: 0.0626 - val_loss: 0.0759 - val_mse: 0.0738\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0636 - mse: 0.0613 - val_loss: 0.0765 - val_mse: 0.0742\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0629 - mse: 0.0604 - val_loss: 0.0775 - val_mse: 0.0750\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0622 - mse: 0.0596 - val_loss: 0.0784 - val_mse: 0.0758\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0617 - mse: 0.0590 - val_loss: 0.0798 - val_mse: 0.0770\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0612 - mse: 0.0584 - val_loss: 0.0793 - val_mse: 0.0764\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0872 - mse: 0.0871 - val_loss: 0.0744 - val_mse: 0.0740\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0705 - mse: 0.0699 - val_loss: 0.0730 - val_mse: 0.0721\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0678 - mse: 0.0666 - val_loss: 0.0734 - val_mse: 0.0720\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0664 - mse: 0.0647 - val_loss: 0.0742 - val_mse: 0.0724\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0652 - mse: 0.0633 - val_loss: 0.0755 - val_mse: 0.0734\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0644 - mse: 0.0622 - val_loss: 0.0764 - val_mse: 0.0741\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0638 - mse: 0.0614 - val_loss: 0.0773 - val_mse: 0.0748\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0633 - mse: 0.0607 - val_loss: 0.0778 - val_mse: 0.0751\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0628 - mse: 0.0600 - val_loss: 0.0781 - val_mse: 0.0753\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0624 - mse: 0.0595 - val_loss: 0.0787 - val_mse: 0.0758\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0874 - mse: 0.0872 - val_loss: 0.0743 - val_mse: 0.0738\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0699 - mse: 0.0691 - val_loss: 0.0733 - val_mse: 0.0722\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0677 - mse: 0.0663 - val_loss: 0.0742 - val_mse: 0.0726\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0664 - mse: 0.0646 - val_loss: 0.0745 - val_mse: 0.0726\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0654 - mse: 0.0633 - val_loss: 0.0755 - val_mse: 0.0733\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0647 - mse: 0.0623 - val_loss: 0.0775 - val_mse: 0.0750\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0642 - mse: 0.0615 - val_loss: 0.0768 - val_mse: 0.0741\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0636 - mse: 0.0608 - val_loss: 0.0781 - val_mse: 0.0753\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0632 - mse: 0.0603 - val_loss: 0.0782 - val_mse: 0.0753\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0628 - mse: 0.0597 - val_loss: 0.0783 - val_mse: 0.0753\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0900 - mse: 0.0899 - val_loss: 0.0773 - val_mse: 0.0771\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0724 - mse: 0.0720 - val_loss: 0.0739 - val_mse: 0.0732\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0689 - mse: 0.0679 - val_loss: 0.0737 - val_mse: 0.0725\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0670 - mse: 0.0656 - val_loss: 0.0741 - val_mse: 0.0724\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0658 - mse: 0.0640 - val_loss: 0.0748 - val_mse: 0.0729\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0650 - mse: 0.0629 - val_loss: 0.0755 - val_mse: 0.0733\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0642 - mse: 0.0618 - val_loss: 0.0771 - val_mse: 0.0747\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0637 - mse: 0.0611 - val_loss: 0.0769 - val_mse: 0.0743\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0631 - mse: 0.0603 - val_loss: 0.0775 - val_mse: 0.0747\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0626 - mse: 0.0598 - val_loss: 0.0790 - val_mse: 0.0761\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0862 - mse: 0.0860 - val_loss: 0.0744 - val_mse: 0.0740\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0704 - mse: 0.0696 - val_loss: 0.0731 - val_mse: 0.0721\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0676 - mse: 0.0663 - val_loss: 0.0739 - val_mse: 0.0724\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0659 - mse: 0.0642 - val_loss: 0.0745 - val_mse: 0.0727\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0648 - mse: 0.0627 - val_loss: 0.0761 - val_mse: 0.0740\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0639 - mse: 0.0617 - val_loss: 0.0766 - val_mse: 0.0743\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0633 - mse: 0.0609 - val_loss: 0.0780 - val_mse: 0.0755\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0627 - mse: 0.0601 - val_loss: 0.0790 - val_mse: 0.0764\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0621 - mse: 0.0595 - val_loss: 0.0791 - val_mse: 0.0765\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0617 - mse: 0.0590 - val_loss: 0.0805 - val_mse: 0.0778\n"
     ]
    }
   ],
   "source": [
    "dnn_dropout_dict={}\n",
    "for x in param_grid['dnn_dropout']:\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(4,4),seed=1024, dnn_dropout=x, dnn_activation='relu',task='binary',\n",
    "                   fm_group=['default_group'],dnn_use_bn=False)\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    \n",
    "    dnn_dropout_dict[x]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),2),\n",
    "      \"AUC\" : np.round(auc,3)}\n",
    "result['dnn_dropout']=dnn_dropout_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "thorough-ribbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'RMSE': 0.29, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.753},\n",
       " 0.1: {'RMSE': 0.27, 'MAE': 0.13, 'MSE': 0.08, 'AUC': 0.763},\n",
       " 0.3: {'RMSE': 0.27, 'MAE': 0.14, 'MSE': 0.07, 'AUC': 0.769},\n",
       " 0.7: {'RMSE': 0.27, 'MAE': 0.14, 'MSE': 0.07, 'AUC': 0.77},\n",
       " 0.9: {'RMSE': 0.27, 'MAE': 0.15, 'MSE': 0.08, 'AUC': 0.772},\n",
       " 0.11: {'RMSE': 0.28, 'MAE': 0.14, 'MSE': 0.08, 'AUC': 0.761}}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_dropout_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "southwest-walnut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.27, 'MAE': 0.14, 'MSE': 0.07, 'AUC': 0.77}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_dropout_dict[.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-paris",
   "metadata": {},
   "source": [
    "## Model after all Hyper-parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "upper-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(4,4)\n",
    "            ,  l2_reg_linear=1e-05, l2_reg_embedding=0.001,seed=1024, dnn_dropout=0.7, dnn_activation='relu',task='binary',\n",
    "               fm_group=['default_group'],l2_reg_dnn=0, dnn_use_bn=False)\n",
    "\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "improved-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 - 3s - loss: 0.0932 - mse: 0.0915 - val_loss: 0.0755 - val_mse: 0.0732\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0758 - mse: 0.0735 - val_loss: 0.0737 - val_mse: 0.0716\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0739 - mse: 0.0719 - val_loss: 0.0728 - val_mse: 0.0708\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0727 - mse: 0.0707 - val_loss: 0.0722 - val_mse: 0.0703\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0718 - mse: 0.0698 - val_loss: 0.0720 - val_mse: 0.0701\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0711 - mse: 0.0690 - val_loss: 0.0721 - val_mse: 0.0699\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0706 - mse: 0.0684 - val_loss: 0.0719 - val_mse: 0.0697\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0701 - mse: 0.0679 - val_loss: 0.0720 - val_mse: 0.0698\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0698 - mse: 0.0675 - val_loss: 0.0718 - val_mse: 0.0696\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0694 - mse: 0.0671 - val_loss: 0.0719 - val_mse: 0.0696\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "altered-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "auc = roc_auc_score(test[target].values, pred_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "nearby-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t0.270000\n",
      "MAE:\t0.150000\n",
      "MSE:\t0.070000\n",
      "AUC score:\t0.770000\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\\t%f\" % np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\"MAE:\\t%f\" % np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE:\\t%f\" % np.round(mean_squared_error(test[target].values, pred_result),2),\"AUC score:\\t%f\" % np.round(auc,2), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-welcome",
   "metadata": {},
   "source": [
    "# ROC Curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "pursuant-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "# tpr Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "# thresholds Decreasing thresholds on the decision function used to compute fpr and tpr.\n",
    "# pos_label The label of the positive class. \n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test[target].values, pred_result, pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "expressed-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr :  [0.00000000e+00 3.33333333e-05 2.06666667e-03 ... 9.99433333e-01\n",
      " 9.99500000e-01 1.00000000e+00]\n",
      "tpr :  [nan nan nan ... nan nan nan]\n",
      "thresholds [1.6435083  0.6435083  0.42077392 ... 0.00701129 0.00700498 0.00452098]\n"
     ]
    }
   ],
   "source": [
    "print(\"fpr : \", fpr)\n",
    "print(\"tpr : \",  tpr)\n",
    "print(\"thresholds\" , thresholds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "pressing-period",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.50\n",
      "Logistic: ROC AUC=0.77\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(pred_result))]\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = pred_result\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "#lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(test[target].values, ns_probs)\n",
    "lr_auc = roc_auc_score(test[target].values, lr_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.2f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.2f' % (lr_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(test[target].values, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(test[target].values, lr_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-communications",
   "metadata": {},
   "source": [
    "## Recommend Hotel for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "varying-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "hotel = list(df.drop_duplicates(subset='item_id', keep='first').item_id)\n",
    "names = list(df.drop_duplicates(subset='item_id', keep='first').item_id)\n",
    "\n",
    "for i in range(len(hotel)):\n",
    "    rows.append( dict({'name': names[i], 'item_id' : hotel[i], 'user_id' : 1048}))\n",
    "test_data = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "overall-equity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.33  for hotel cluster:  44\n",
      "Score:  0.3  for hotel cluster:  9\n",
      "Score:  0.29  for hotel cluster:  34\n",
      "Score:  0.27  for hotel cluster:  1\n",
      "Score:  0.26  for hotel cluster:  21\n"
     ]
    }
   ],
   "source": [
    "for idx, (score, name) in enumerate(sorted(zip(pred_result, names), reverse=True)):\n",
    "    if idx >= 5:\n",
    "        break\n",
    " \n",
    "    print(\"Score: \", round(float(score), 2), \" for hotel cluster: \", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-belle",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR\n",
    "\n",
    "https://deepctr-doc.readthedocs.io/en/latest/deepctr.models.deepfm.html\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR/blob/ce140ffcc1057e8fb57622ae1732c39df32bc11e/docs/source/FAQ.md\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR/blob/db229dc31f0d4c79c0de2ece0bb919b35258d6b2/examples/run_regression_movielens.py\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR/blob/db229dc31f0d4c79c0de2ece0bb919b35258d6b2/examples/run_multivalue_movielens.py\n",
    "\n",
    "https://deepctr-doc.readthedocs.io/en/latest/Examples.html#classification-criteo\n",
    "\n",
    "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-glenn",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
