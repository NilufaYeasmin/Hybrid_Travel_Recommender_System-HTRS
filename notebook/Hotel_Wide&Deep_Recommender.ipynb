{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smaller-darwin",
   "metadata": {},
   "source": [
    "# Expedia Hotel Recommender System- Wide and Deep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-dominant",
   "metadata": {},
   "source": [
    "## Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "simple-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deepctr.layers.core import PredictionLayer, DNN\n",
    "from deepctr.layers.utils import add_func\n",
    "from deepctr.models import WDL\n",
    "\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat,get_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-testimony",
   "metadata": {},
   "source": [
    "# Reading and Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "banner-drilling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 24)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"..\\data\\\\train.csv\", sep=',', nrows=150000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "statistical-internship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>is_booking</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-11 07:46:59</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11 08:22:12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time  site_name  posa_continent  user_location_country  \\\n",
       "0  2014-08-11 07:46:59          2               3                     66   \n",
       "1  2014-08-11 08:22:12          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   348               48862                  2234.2641   \n",
       "1                   348               48862                  2234.2641   \n",
       "\n",
       "   user_id  is_mobile  is_package  ...  srch_children_cnt srch_rm_cnt  \\\n",
       "0       12          0           1  ...                  0           1   \n",
       "1       12          0           1  ...                  0           1   \n",
       "\n",
       "  srch_destination_id  srch_destination_type_id  is_booking  cnt  \\\n",
       "0                8250                         1           0    3   \n",
       "1                8250                         1           1    1   \n",
       "\n",
       "   hotel_continent  hotel_country  hotel_market  hotel_cluster  \n",
       "0                2             50           628              1  \n",
       "1                2             50           628              1  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "skilled-halifax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   date_time                  150000 non-null  object \n",
      " 1   site_name                  150000 non-null  int64  \n",
      " 2   posa_continent             150000 non-null  int64  \n",
      " 3   user_location_country      150000 non-null  int64  \n",
      " 4   user_location_region       150000 non-null  int64  \n",
      " 5   user_location_city         150000 non-null  int64  \n",
      " 6   orig_destination_distance  97558 non-null   float64\n",
      " 7   user_id                    150000 non-null  int64  \n",
      " 8   is_mobile                  150000 non-null  int64  \n",
      " 9   is_package                 150000 non-null  int64  \n",
      " 10  channel                    150000 non-null  int64  \n",
      " 11  srch_ci                    149875 non-null  object \n",
      " 12  srch_co                    149875 non-null  object \n",
      " 13  srch_adults_cnt            150000 non-null  int64  \n",
      " 14  srch_children_cnt          150000 non-null  int64  \n",
      " 15  srch_rm_cnt                150000 non-null  int64  \n",
      " 16  srch_destination_id        150000 non-null  int64  \n",
      " 17  srch_destination_type_id   150000 non-null  int64  \n",
      " 18  is_booking                 150000 non-null  int64  \n",
      " 19  cnt                        150000 non-null  int64  \n",
      " 20  hotel_continent            150000 non-null  int64  \n",
      " 21  hotel_country              150000 non-null  int64  \n",
      " 22  hotel_market               150000 non-null  int64  \n",
      " 23  hotel_cluster              150000 non-null  int64  \n",
      "dtypes: float64(1), int64(20), object(3)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "specialized-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract month from date_time\n",
    "df['checkin_month'] = pd.DatetimeIndex(df['srch_ci']).month\n",
    "df['checkout_month'] = pd.DatetimeIndex(df['srch_co']).month\n",
    "df['click_month'] = pd.DatetimeIndex(df['date_time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "white-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(['date_time'],axis=1)\n",
    "df= df.drop(['srch_ci'],axis=1)\n",
    "df= df.drop(['srch_co'],axis=1)\n",
    "df= df.drop(['orig_destination_distance'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "opposed-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df = df.rename(columns={'hotel_cluster': 'item_id', 'is_booking': 'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "negative-heather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   site_name                 150000 non-null  int64  \n",
      " 1   posa_continent            150000 non-null  int64  \n",
      " 2   user_location_country     150000 non-null  int64  \n",
      " 3   user_location_region      150000 non-null  int64  \n",
      " 4   user_location_city        150000 non-null  int64  \n",
      " 5   user_id                   150000 non-null  int64  \n",
      " 6   is_mobile                 150000 non-null  int64  \n",
      " 7   is_package                150000 non-null  int64  \n",
      " 8   channel                   150000 non-null  int64  \n",
      " 9   srch_adults_cnt           150000 non-null  int64  \n",
      " 10  srch_children_cnt         150000 non-null  int64  \n",
      " 11  srch_rm_cnt               150000 non-null  int64  \n",
      " 12  srch_destination_id       150000 non-null  int64  \n",
      " 13  srch_destination_type_id  150000 non-null  int64  \n",
      " 14  rating                    150000 non-null  int64  \n",
      " 15  cnt                       150000 non-null  int64  \n",
      " 16  hotel_continent           150000 non-null  int64  \n",
      " 17  hotel_country             150000 non-null  int64  \n",
      " 18  hotel_market              150000 non-null  float64\n",
      " 19  item_id                   150000 non-null  int64  \n",
      " 20  checkin_month             150000 non-null  int64  \n",
      " 21  checkout_month            150000 non-null  int64  \n",
      " 22  click_month               150000 non-null  int64  \n",
      "dtypes: float64(1), int64(22)\n",
      "memory usage: 26.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-category",
   "metadata": {},
   "source": [
    "### Sparse Features/ Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "flying-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categ_sparse \n",
    "sparse_features = ['site_name','posa_continent','user_location_country','user_location_region','user_location_city',\n",
    "             'user_id','is_mobile','is_package','channel','click_month','checkin_month','checkout_month',\n",
    "            'srch_adults_cnt','srch_children_cnt','srch_rm_cnt','srch_destination_id','hotel_continent',\n",
    "               'hotel_country','cnt','click_month', 'checkin_month','checkout_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-franklin",
   "metadata": {},
   "source": [
    "### Dense Features/ Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "generic-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features = ['hotel_market']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-checklist",
   "metadata": {},
   "source": [
    "### Target Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "friendly-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-lancaster",
   "metadata": {},
   "source": [
    "## Simple preprocessing\n",
    "\n",
    "Usually we have two methods to encode the sparse categorical feature for embedding\n",
    "\n",
    "**Label Encoding: map the features to integer value from 0 ~ len(#unique) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cutting-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for sparse features,and normalization for dense numerical features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    df[feat] = lbe.fit_transform(df[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-holiday",
   "metadata": {},
   "source": [
    "### Here we use normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "premium-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "df[dense_features] = mms.fit_transform(df[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-indianapolis",
   "metadata": {},
   "source": [
    "## Generate feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-warren",
   "metadata": {},
   "source": [
    "For sparse features, we transform them into dense vectors by embedding techniques. For dense numerical features, we concatenate them to the input tensors of fully connected layer.\n",
    "\n",
    "**Label Encoding and Generate feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "essential-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=df[feat].nunique(),embedding_dim=4)\n",
    "                       for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
    "                      for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-notion",
   "metadata": {},
   "source": [
    "## Generate the training samples and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "subjective-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-youth",
   "metadata": {},
   "source": [
    "## Define Model and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "abstract-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_feature_columns: An iterable containing all the features used by linear part of the model.\n",
    "\n",
    "model = WDL(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(128, 128), l2_reg_linear=1e-05,\n",
    "        l2_reg_embedding=1e-05, l2_reg_dnn=0, seed=1024, dnn_dropout=0, dnn_activation='relu',\n",
    "        task='binary')\n",
    "\n",
    "\n",
    "model.compile(\"adam\", \"mse\",metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "aquatic-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.0778 - mse: 0.0775 - val_loss: 0.0698 - val_mse: 0.0693\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0668 - mse: 0.0660 - val_loss: 0.0716 - val_mse: 0.0707\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.0643 - mse: 0.0631 - val_loss: 0.0736 - val_mse: 0.0723\n",
      "Epoch 4/10\n",
      "375/375 - 3s - loss: 0.0624 - mse: 0.0611 - val_loss: 0.0759 - val_mse: 0.0743\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.0612 - mse: 0.0596 - val_loss: 0.0779 - val_mse: 0.0762\n",
      "Epoch 6/10\n",
      "375/375 - 3s - loss: 0.0603 - mse: 0.0586 - val_loss: 0.0794 - val_mse: 0.0776\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0595 - mse: 0.0577 - val_loss: 0.0813 - val_mse: 0.0795\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0588 - mse: 0.0569 - val_loss: 0.0809 - val_mse: 0.0790\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0582 - mse: 0.0563 - val_loss: 0.0833 - val_mse: 0.0813\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0574 - mse: 0.0554 - val_loss: 0.0840 - val_mse: 0.0820\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "searching-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "pred_result = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "straight-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t0.284000\n",
      "MAE:\t0.126000\n",
      "MSE:\t0.081000\n",
      "AUC:\t0.752000\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test[target].values, pred_result)\n",
    "\n",
    "print(\"RMSE:\\t%f\" % np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),3),\"MAE:\\t%f\" % np.round(mean_absolute_error(test[target].values, pred_result),3),\n",
    "      \"MSE:\\t%f\" % np.round(mean_squared_error(test[target].values, pred_result),3),\"AUC:\\t%f\" % np.round(auc,3),sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-gauge",
   "metadata": {},
   "source": [
    "## Let's Experiments on Hyper-parameters tuning and see their effect on model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-novelty",
   "metadata": {},
   "source": [
    "### Instantiates the Wide&Deep Learning architecture.\n",
    "\n",
    "#### Parameters:\t\n",
    "\n",
    "linear_feature_columns â€“ An iterable containing all the features used by linear part of the model.\n",
    "\n",
    "dnn_feature_columns â€“ An iterable containing all the features used by deep part of the model.\n",
    "\n",
    "dnn_hidden_units â€“ list,list of positive integer or empty list, the layer number and units in each layer of DNN\n",
    "\n",
    "l2_reg_linear â€“ float. L2 regularizer strength applied to wide part\n",
    "\n",
    "l2_reg_embedding â€“ float. L2 regularizer strength applied to embedding vector\n",
    "\n",
    "l2_reg_dnn â€“ float. L2 regularizer strength applied to DNN\n",
    "\n",
    "seed â€“ integer ,to use as random seed.\n",
    "\n",
    "dnn_dropout â€“ float in [0,1), the probability we will drop out a given DNN coordinate.\n",
    "\n",
    "dnn_activation â€“ Activation function to use in DNN\n",
    "\n",
    "task â€“ str, \"binary\" for binary logloss or \"regression\" for regression loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-optimum",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters with GridSearch\n",
    "\n",
    "Grid search, which is an optimization scheme trying all possible combinations of specified hyperparameter choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "favorite-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'dnn_hidden_units' : [(1,1),(2,2),(3,3),(8,8),(17,17),(128,128),(256,256)],\n",
    "              'l2_reg_linear':[1e-05,1e-3,.1, 1, 10],\n",
    "              'l2_reg_embedding':[1e-7,1e-5,1e-3,1e-1,1],\n",
    "              'l2_reg_dnn':[0,0.2,2,4],\n",
    "              'dnn_dropout':np.arange(0, 1, .1)\n",
    "             }\n",
    "result = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-hybrid",
   "metadata": {},
   "source": [
    "### dnn_hidden_units â€“ list,list of positive integer or empty list, the layer number and units in each layer of DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "smoking-green",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0911 - mse: 0.0910 - val_loss: 0.0755 - val_mse: 0.0754\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0748 - mse: 0.0747 - val_loss: 0.0743 - val_mse: 0.0741\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0734 - mse: 0.0732 - val_loss: 0.0733 - val_mse: 0.0730\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0722 - mse: 0.0719 - val_loss: 0.0726 - val_mse: 0.0721\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0713 - mse: 0.0708 - val_loss: 0.0721 - val_mse: 0.0715\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0706 - mse: 0.0699 - val_loss: 0.0719 - val_mse: 0.0711\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0701 - mse: 0.0692 - val_loss: 0.0717 - val_mse: 0.0708\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0697 - mse: 0.0687 - val_loss: 0.0717 - val_mse: 0.0706\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0694 - mse: 0.0683 - val_loss: 0.0717 - val_mse: 0.0705\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0692 - mse: 0.0679 - val_loss: 0.0717 - val_mse: 0.0704\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 5s - loss: 0.0880 - mse: 0.0878 - val_loss: 0.0749 - val_mse: 0.0746\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0729 - mse: 0.0724 - val_loss: 0.0714 - val_mse: 0.0707\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0693 - mse: 0.0682 - val_loss: 0.0709 - val_mse: 0.0696\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0669 - mse: 0.0654 - val_loss: 0.0719 - val_mse: 0.0702\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0652 - mse: 0.0634 - val_loss: 0.0735 - val_mse: 0.0716\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0639 - mse: 0.0620 - val_loss: 0.0749 - val_mse: 0.0729\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0627 - mse: 0.0607 - val_loss: 0.0762 - val_mse: 0.0741\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0618 - mse: 0.0597 - val_loss: 0.0773 - val_mse: 0.0752\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0611 - mse: 0.0589 - val_loss: 0.0800 - val_mse: 0.0778\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0604 - mse: 0.0582 - val_loss: 0.0795 - val_mse: 0.0773\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.0881 - mse: 0.0879 - val_loss: 0.0745 - val_mse: 0.0742\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0712 - mse: 0.0705 - val_loss: 0.0707 - val_mse: 0.0696\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0669 - mse: 0.0657 - val_loss: 0.0720 - val_mse: 0.0706\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0649 - mse: 0.0633 - val_loss: 0.0737 - val_mse: 0.0720\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0634 - mse: 0.0616 - val_loss: 0.0755 - val_mse: 0.0736\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0623 - mse: 0.0603 - val_loss: 0.0769 - val_mse: 0.0750\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0613 - mse: 0.0593 - val_loss: 0.0784 - val_mse: 0.0764\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0606 - mse: 0.0585 - val_loss: 0.0798 - val_mse: 0.0777\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0600 - mse: 0.0579 - val_loss: 0.0801 - val_mse: 0.0779\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0595 - mse: 0.0574 - val_loss: 0.0821 - val_mse: 0.0799\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.0880 - mse: 0.0879 - val_loss: 0.0718 - val_mse: 0.0714\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0694 - mse: 0.0685 - val_loss: 0.0706 - val_mse: 0.0694\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.0661 - mse: 0.0647 - val_loss: 0.0730 - val_mse: 0.0715\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0643 - mse: 0.0626 - val_loss: 0.0742 - val_mse: 0.0725\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0628 - mse: 0.0610 - val_loss: 0.0766 - val_mse: 0.0747\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0617 - mse: 0.0598 - val_loss: 0.0780 - val_mse: 0.0760\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0608 - mse: 0.0588 - val_loss: 0.0786 - val_mse: 0.0765\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0603 - mse: 0.0582 - val_loss: 0.0801 - val_mse: 0.0780\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0597 - mse: 0.0575 - val_loss: 0.0819 - val_mse: 0.0797\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0592 - mse: 0.0570 - val_loss: 0.0820 - val_mse: 0.0798\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0847 - mse: 0.0845 - val_loss: 0.0703 - val_mse: 0.0697\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0682 - mse: 0.0673 - val_loss: 0.0713 - val_mse: 0.0702\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0652 - mse: 0.0640 - val_loss: 0.0730 - val_mse: 0.0716\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0633 - mse: 0.0618 - val_loss: 0.0750 - val_mse: 0.0734\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0620 - mse: 0.0603 - val_loss: 0.0763 - val_mse: 0.0746\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0609 - mse: 0.0591 - val_loss: 0.0780 - val_mse: 0.0762\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0601 - mse: 0.0583 - val_loss: 0.0803 - val_mse: 0.0784\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0594 - mse: 0.0575 - val_loss: 0.0817 - val_mse: 0.0798\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0589 - mse: 0.0569 - val_loss: 0.0815 - val_mse: 0.0795\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0584 - mse: 0.0564 - val_loss: 0.0844 - val_mse: 0.0824\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.0775 - mse: 0.0772 - val_loss: 0.0697 - val_mse: 0.0692\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0667 - mse: 0.0659 - val_loss: 0.0720 - val_mse: 0.0711\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.0641 - mse: 0.0631 - val_loss: 0.0735 - val_mse: 0.0722\n",
      "Epoch 4/10\n",
      "375/375 - 3s - loss: 0.0623 - mse: 0.0610 - val_loss: 0.0759 - val_mse: 0.0744\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.0611 - mse: 0.0596 - val_loss: 0.0769 - val_mse: 0.0753\n",
      "Epoch 6/10\n",
      "375/375 - 3s - loss: 0.0600 - mse: 0.0584 - val_loss: 0.0807 - val_mse: 0.0789\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0592 - mse: 0.0574 - val_loss: 0.0801 - val_mse: 0.0783\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0584 - mse: 0.0565 - val_loss: 0.0824 - val_mse: 0.0805\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0575 - mse: 0.0556 - val_loss: 0.0842 - val_mse: 0.0822\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0569 - mse: 0.0549 - val_loss: 0.0863 - val_mse: 0.0843\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.0764 - mse: 0.0761 - val_loss: 0.0698 - val_mse: 0.0693\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0666 - mse: 0.0658 - val_loss: 0.0712 - val_mse: 0.0703\n",
      "Epoch 3/10\n",
      "375/375 - 4s - loss: 0.0640 - mse: 0.0629 - val_loss: 0.0736 - val_mse: 0.0724\n",
      "Epoch 4/10\n",
      "375/375 - 4s - loss: 0.0624 - mse: 0.0610 - val_loss: 0.0756 - val_mse: 0.0742\n",
      "Epoch 5/10\n",
      "375/375 - 6s - loss: 0.0611 - mse: 0.0596 - val_loss: 0.0768 - val_mse: 0.0752\n",
      "Epoch 6/10\n",
      "375/375 - 4s - loss: 0.0603 - mse: 0.0586 - val_loss: 0.0786 - val_mse: 0.0769\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0595 - mse: 0.0577 - val_loss: 0.0809 - val_mse: 0.0791\n",
      "Epoch 8/10\n",
      "375/375 - 4s - loss: 0.0587 - mse: 0.0569 - val_loss: 0.0806 - val_mse: 0.0787\n",
      "Epoch 9/10\n",
      "375/375 - 4s - loss: 0.0579 - mse: 0.0560 - val_loss: 0.0830 - val_mse: 0.0810\n",
      "Epoch 10/10\n",
      "375/375 - 4s - loss: 0.0573 - mse: 0.0554 - val_loss: 0.0844 - val_mse: 0.0823\n"
     ]
    }
   ],
   "source": [
    "dnn_hidden_units_dict = {}\n",
    "for i in param_grid['dnn_hidden_units']:\n",
    "    model = WDL(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=i, \n",
    "              seed=1024,task='binary')\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    \n",
    "    #model prediction\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    #model evaluation RMSE, MAE,MSE\n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    dnn_hidden_units_dict[i]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),3),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),3),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),3),\n",
    "      \"AUC\" : np.round(auc,3)}\n",
    "result['dnn_hidden_units_dict']=dnn_hidden_units_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "beneficial-thickness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): {'RMSE': 0.266, 'MAE': 0.155, 'MSE': 0.071, 'AUC': 0.772},\n",
       " (2, 2): {'RMSE': 0.277, 'MAE': 0.136, 'MSE': 0.077, 'AUC': 0.757},\n",
       " (3, 3): {'RMSE': 0.281, 'MAE': 0.142, 'MSE': 0.079, 'AUC': 0.757},\n",
       " (8, 8): {'RMSE': 0.281, 'MAE': 0.136, 'MSE': 0.079, 'AUC': 0.754},\n",
       " (17, 17): {'RMSE': 0.285, 'MAE': 0.145, 'MSE': 0.081, 'AUC': 0.755},\n",
       " (128, 128): {'RMSE': 0.289, 'MAE': 0.136, 'MSE': 0.083, 'AUC': 0.75},\n",
       " (256, 256): {'RMSE': 0.285, 'MAE': 0.132, 'MSE': 0.081, 'AUC': 0.75}}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_hidden_units_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "printable-manitoba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.277, 'MAE': 0.136, 'MSE': 0.077, 'AUC': 0.757}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_hidden_units_dict[(2,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-powder",
   "metadata": {},
   "source": [
    "### l2_reg_linear â€“ float. L2 regularizer strength applied to wide part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "resident-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 5s - loss: 0.0862 - mse: 0.0860 - val_loss: 0.0740 - val_mse: 0.0737\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0715 - mse: 0.0709 - val_loss: 0.0708 - val_mse: 0.0699\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.0680 - mse: 0.0668 - val_loss: 0.0711 - val_mse: 0.0697\n",
      "Epoch 4/10\n",
      "375/375 - 3s - loss: 0.0659 - mse: 0.0643 - val_loss: 0.0724 - val_mse: 0.0707\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.0643 - mse: 0.0625 - val_loss: 0.0744 - val_mse: 0.0726\n",
      "Epoch 6/10\n",
      "375/375 - 3s - loss: 0.0630 - mse: 0.0611 - val_loss: 0.0762 - val_mse: 0.0742\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0620 - mse: 0.0600 - val_loss: 0.0772 - val_mse: 0.0752\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0612 - mse: 0.0591 - val_loss: 0.0782 - val_mse: 0.0761\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0605 - mse: 0.0584 - val_loss: 0.0794 - val_mse: 0.0773\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0600 - mse: 0.0579 - val_loss: 0.0793 - val_mse: 0.0771\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 5s - loss: 0.0854 - mse: 0.0845 - val_loss: 0.0743 - val_mse: 0.0735\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0714 - mse: 0.0703 - val_loss: 0.0709 - val_mse: 0.0696\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.0676 - mse: 0.0661 - val_loss: 0.0720 - val_mse: 0.0703\n",
      "Epoch 4/10\n",
      "375/375 - 3s - loss: 0.0654 - mse: 0.0637 - val_loss: 0.0736 - val_mse: 0.0718\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.0638 - mse: 0.0620 - val_loss: 0.0753 - val_mse: 0.0733\n",
      "Epoch 6/10\n",
      "375/375 - 3s - loss: 0.0626 - mse: 0.0606 - val_loss: 0.0770 - val_mse: 0.0750\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0616 - mse: 0.0596 - val_loss: 0.0785 - val_mse: 0.0765\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0609 - mse: 0.0589 - val_loss: 0.0798 - val_mse: 0.0778\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0603 - mse: 0.0583 - val_loss: 0.0799 - val_mse: 0.0778\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0599 - mse: 0.0578 - val_loss: 0.0809 - val_mse: 0.0788\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 6s - loss: 0.1016 - mse: 0.0916 - val_loss: 0.0762 - val_mse: 0.0748\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0740 - mse: 0.0731 - val_loss: 0.0723 - val_mse: 0.0713\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.0708 - mse: 0.0696 - val_loss: 0.0711 - val_mse: 0.0697\n",
      "Epoch 4/10\n",
      "375/375 - 4s - loss: 0.0687 - mse: 0.0670 - val_loss: 0.0714 - val_mse: 0.0696\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.0670 - mse: 0.0650 - val_loss: 0.0724 - val_mse: 0.0703\n",
      "Epoch 6/10\n",
      "375/375 - 3s - loss: 0.0656 - mse: 0.0634 - val_loss: 0.0733 - val_mse: 0.0712\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0644 - mse: 0.0622 - val_loss: 0.0749 - val_mse: 0.0727\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0634 - mse: 0.0611 - val_loss: 0.0756 - val_mse: 0.0733\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0625 - mse: 0.0601 - val_loss: 0.0767 - val_mse: 0.0744\n",
      "Epoch 10/10\n",
      "375/375 - 4s - loss: 0.0618 - mse: 0.0594 - val_loss: 0.0781 - val_mse: 0.0757\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 5s - loss: 0.1331 - mse: 0.0924 - val_loss: 0.0788 - val_mse: 0.0745\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0740 - mse: 0.0726 - val_loss: 0.0717 - val_mse: 0.0708\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.0695 - mse: 0.0683 - val_loss: 0.0709 - val_mse: 0.0695\n",
      "Epoch 4/10\n",
      "375/375 - 4s - loss: 0.0672 - mse: 0.0655 - val_loss: 0.0718 - val_mse: 0.0700\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.0655 - mse: 0.0636 - val_loss: 0.0734 - val_mse: 0.0715\n",
      "Epoch 6/10\n",
      "375/375 - 3s - loss: 0.0642 - mse: 0.0622 - val_loss: 0.0746 - val_mse: 0.0725\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0631 - mse: 0.0610 - val_loss: 0.0761 - val_mse: 0.0740\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0622 - mse: 0.0600 - val_loss: 0.0772 - val_mse: 0.0751\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0614 - mse: 0.0591 - val_loss: 0.0784 - val_mse: 0.0762\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0608 - mse: 0.0586 - val_loss: 0.0792 - val_mse: 0.0770\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 8s - loss: 0.4789 - mse: 0.1070 - val_loss: 0.1185 - val_mse: 0.0754\n",
      "Epoch 2/10\n",
      "375/375 - 3s - loss: 0.0839 - mse: 0.0747 - val_loss: 0.0744 - val_mse: 0.0735\n",
      "Epoch 3/10\n",
      "375/375 - 4s - loss: 0.0724 - mse: 0.0714 - val_loss: 0.0714 - val_mse: 0.0701\n",
      "Epoch 4/10\n",
      "375/375 - 3s - loss: 0.0691 - mse: 0.0674 - val_loss: 0.0716 - val_mse: 0.0698\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.0669 - mse: 0.0650 - val_loss: 0.0727 - val_mse: 0.0706\n",
      "Epoch 6/10\n",
      "375/375 - 3s - loss: 0.0654 - mse: 0.0633 - val_loss: 0.0739 - val_mse: 0.0718\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0642 - mse: 0.0619 - val_loss: 0.0751 - val_mse: 0.0728\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0632 - mse: 0.0608 - val_loss: 0.0761 - val_mse: 0.0738\n",
      "Epoch 9/10\n",
      "375/375 - 4s - loss: 0.0622 - mse: 0.0599 - val_loss: 0.0774 - val_mse: 0.0750\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0616 - mse: 0.0592 - val_loss: 0.0783 - val_mse: 0.0759\n"
     ]
    }
   ],
   "source": [
    "l2_reg_linear_dict={}\n",
    "for i in param_grid['l2_reg_linear']:\n",
    "    model = WDL(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(2,2), l2_reg_linear=i,\n",
    "            l2_reg_embedding=1e-5, l2_reg_dnn=0, seed=1024,task='binary')\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    #model prediction\n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    \n",
    "     #model evaluation RMSE, MAE,MSE\n",
    "    l2_reg_linear_dict[i]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),3),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),3),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),3),\n",
    "      \"AUC\" : np.round(auc,3)}\n",
    "    \n",
    "result['l2_reg_linear']=l2_reg_linear_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "judicial-artist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-05: {'RMSE': 0.277, 'MAE': 0.131, 'MSE': 0.077, 'AUC': 0.755},\n",
       " 0.001: {'RMSE': 0.28, 'MAE': 0.134, 'MSE': 0.078, 'AUC': 0.758},\n",
       " 0.1: {'RMSE': 0.274, 'MAE': 0.136, 'MSE': 0.075, 'AUC': 0.766},\n",
       " 1: {'RMSE': 0.277, 'MAE': 0.135, 'MSE': 0.076, 'AUC': 0.76},\n",
       " 10: {'RMSE': 0.275, 'MAE': 0.141, 'MSE': 0.076, 'AUC': 0.763}}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_linear_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "medieval-quarterly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.274, 'MAE': 0.136, 'MSE': 0.075, 'AUC': 0.766}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_linear_dict[.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-newfoundland",
   "metadata": {},
   "source": [
    "### l2_reg_embedding â€“ float. L2 regularizer strength applied to embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "listed-value",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.1014 - mse: 0.0917 - val_loss: 0.0752 - val_mse: 0.0743\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0716 - mse: 0.0713 - val_loss: 0.0703 - val_mse: 0.0701\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0664 - mse: 0.0661 - val_loss: 0.0704 - val_mse: 0.0702\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0632 - mse: 0.0629 - val_loss: 0.0724 - val_mse: 0.0721\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0610 - mse: 0.0607 - val_loss: 0.0742 - val_mse: 0.0739\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0594 - mse: 0.0591 - val_loss: 0.0756 - val_mse: 0.0752\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0583 - mse: 0.0579 - val_loss: 0.0765 - val_mse: 0.0762\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0575 - mse: 0.0571 - val_loss: 0.0775 - val_mse: 0.0772\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0568 - mse: 0.0564 - val_loss: 0.0789 - val_mse: 0.0785\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0563 - mse: 0.0559 - val_loss: 0.0798 - val_mse: 0.0794\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.0933 - mse: 0.0864 - val_loss: 0.0744 - val_mse: 0.0736\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0716 - mse: 0.0708 - val_loss: 0.0708 - val_mse: 0.0697\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0681 - mse: 0.0667 - val_loss: 0.0714 - val_mse: 0.0699\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0660 - mse: 0.0643 - val_loss: 0.0728 - val_mse: 0.0710\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0645 - mse: 0.0625 - val_loss: 0.0743 - val_mse: 0.0723\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0633 - mse: 0.0612 - val_loss: 0.0758 - val_mse: 0.0737\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0623 - mse: 0.0601 - val_loss: 0.0767 - val_mse: 0.0746\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0615 - mse: 0.0593 - val_loss: 0.0789 - val_mse: 0.0767\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0608 - mse: 0.0586 - val_loss: 0.0788 - val_mse: 0.0765\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0604 - mse: 0.0582 - val_loss: 0.0795 - val_mse: 0.0773\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.0971 - mse: 0.0879 - val_loss: 0.0780 - val_mse: 0.0753\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0766 - mse: 0.0744 - val_loss: 0.0753 - val_mse: 0.0733\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0752 - mse: 0.0731 - val_loss: 0.0746 - val_mse: 0.0724\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0746 - mse: 0.0721 - val_loss: 0.0742 - val_mse: 0.0715\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0742 - mse: 0.0712 - val_loss: 0.0739 - val_mse: 0.0707\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0739 - mse: 0.0706 - val_loss: 0.0736 - val_mse: 0.0704\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0736 - mse: 0.0702 - val_loss: 0.0736 - val_mse: 0.0701\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0733 - mse: 0.0698 - val_loss: 0.0733 - val_mse: 0.0700\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0730 - mse: 0.0695 - val_loss: 0.0733 - val_mse: 0.0698\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0728 - mse: 0.0693 - val_loss: 0.0732 - val_mse: 0.0699\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1155 - mse: 0.0982 - val_loss: 0.0888 - val_mse: 0.0796\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0817 - mse: 0.0775 - val_loss: 0.0780 - val_mse: 0.0762\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0775 - mse: 0.0760 - val_loss: 0.0769 - val_mse: 0.0751\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0768 - mse: 0.0752 - val_loss: 0.0770 - val_mse: 0.0746\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0767 - mse: 0.0744 - val_loss: 0.0762 - val_mse: 0.0741\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0767 - mse: 0.0740 - val_loss: 0.0763 - val_mse: 0.0736\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0770 - mse: 0.0736 - val_loss: 0.0774 - val_mse: 0.0731\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0772 - mse: 0.0734 - val_loss: 0.0775 - val_mse: 0.0729\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0775 - mse: 0.0732 - val_loss: 0.0778 - val_mse: 0.0727\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0779 - mse: 0.0731 - val_loss: 0.0775 - val_mse: 0.0728\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1153 - mse: 0.0987 - val_loss: 0.0884 - val_mse: 0.0799\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0811 - mse: 0.0779 - val_loss: 0.0775 - val_mse: 0.0767\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0771 - mse: 0.0765 - val_loss: 0.0767 - val_mse: 0.0762\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0768 - mse: 0.0762 - val_loss: 0.0765 - val_mse: 0.0759\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0767 - mse: 0.0759 - val_loss: 0.0764 - val_mse: 0.0755\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0766 - mse: 0.0756 - val_loss: 0.0765 - val_mse: 0.0751\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0765 - mse: 0.0753 - val_loss: 0.0764 - val_mse: 0.0747\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0764 - mse: 0.0749 - val_loss: 0.0761 - val_mse: 0.0744\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0764 - mse: 0.0746 - val_loss: 0.0759 - val_mse: 0.0744\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0763 - mse: 0.0744 - val_loss: 0.0759 - val_mse: 0.0738\n"
     ]
    }
   ],
   "source": [
    "l2_reg_embedding_dict={}\n",
    "for i in param_grid['l2_reg_embedding']:\n",
    "    model = WDL(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(2,2), l2_reg_linear=.1,\n",
    "            l2_reg_embedding=i, l2_reg_dnn=0,  seed=1024, task='binary')\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    \n",
    "    #model prediction\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    # #model evaluation RMSE, MAE,MSE\n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    l2_reg_embedding_dict[i]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),3),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),3),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),3),\n",
    "      \"AUC\" : np.round(auc,3)}\n",
    "result['l2_reg_embedding']=l2_reg_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "complete-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-07: {'RMSE': 0.281, 'MAE': 0.135, 'MSE': 0.079, 'AUC': 0.749},\n",
       " 1e-05: {'RMSE': 0.277, 'MAE': 0.13, 'MSE': 0.077, 'AUC': 0.757},\n",
       " 0.001: {'RMSE': 0.264, 'MAE': 0.136, 'MSE': 0.07, 'AUC': 0.778},\n",
       " 0.1: {'RMSE': 0.27, 'MAE': 0.162, 'MSE': 0.073, 'AUC': 0.725},\n",
       " 1: {'RMSE': 0.272, 'MAE': 0.157, 'MSE': 0.074, 'AUC': 0.71}}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "worldwide-repair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.264, 'MAE': 0.136, 'MSE': 0.07, 'AUC': 0.778}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_embedding_dict[.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-directive",
   "metadata": {},
   "source": [
    "### l2_reg_dnn â€“ float. L2 regularizer strength applied to DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "express-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1084 - mse: 0.0942 - val_loss: 0.0810 - val_mse: 0.0761\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0769 - mse: 0.0741 - val_loss: 0.0752 - val_mse: 0.0726\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0750 - mse: 0.0722 - val_loss: 0.0743 - val_mse: 0.0714\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0744 - mse: 0.0711 - val_loss: 0.0741 - val_mse: 0.0705\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0740 - mse: 0.0704 - val_loss: 0.0739 - val_mse: 0.0702\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0737 - mse: 0.0700 - val_loss: 0.0735 - val_mse: 0.0701\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0734 - mse: 0.0696 - val_loss: 0.0735 - val_mse: 0.0700\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0731 - mse: 0.0694 - val_loss: 0.0734 - val_mse: 0.0700\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0730 - mse: 0.0692 - val_loss: 0.0732 - val_mse: 0.0697\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0727 - mse: 0.0689 - val_loss: 0.0732 - val_mse: 0.0697\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.5142 - mse: 0.1012 - val_loss: 0.2536 - val_mse: 0.0856\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.1933 - mse: 0.0818 - val_loss: 0.1472 - val_mse: 0.0787\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.1209 - mse: 0.0774 - val_loss: 0.1008 - val_mse: 0.0764\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0908 - mse: 0.0763 - val_loss: 0.0832 - val_mse: 0.0760\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0801 - mse: 0.0762 - val_loss: 0.0777 - val_mse: 0.0760\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0771 - mse: 0.0762 - val_loss: 0.0764 - val_mse: 0.0760\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0764 - mse: 0.0762 - val_loss: 0.0762 - val_mse: 0.0760\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0764 - mse: 0.0762 - val_loss: 0.0761 - val_mse: 0.0760\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0763 - mse: 0.0762 - val_loss: 0.0761 - val_mse: 0.0760\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0763 - mse: 0.0762 - val_loss: 0.0761 - val_mse: 0.0760\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 5.7041 - mse: 0.0973 - val_loss: 2.7291 - val_mse: 0.0832\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 1.8549 - mse: 0.0805 - val_loss: 1.1910 - val_mse: 0.0782\n",
      "Epoch 3/10\n",
      "375/375 - 3s - loss: 0.7969 - mse: 0.0773 - val_loss: 0.4944 - val_mse: 0.0764\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.3289 - mse: 0.0764 - val_loss: 0.2082 - val_mse: 0.0761\n",
      "Epoch 5/10\n",
      "375/375 - 3s - loss: 0.1498 - mse: 0.0762 - val_loss: 0.1097 - val_mse: 0.0760\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0932 - mse: 0.0762 - val_loss: 0.0825 - val_mse: 0.0760\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0792 - mse: 0.0762 - val_loss: 0.0770 - val_mse: 0.0760\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0767 - mse: 0.0762 - val_loss: 0.0762 - val_mse: 0.0760\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0764 - mse: 0.0762 - val_loss: 0.0761 - val_mse: 0.0760\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0764 - mse: 0.0762 - val_loss: 0.0761 - val_mse: 0.0760\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 5.1831 - mse: 0.0992 - val_loss: 1.4805 - val_mse: 0.0843\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.8767 - mse: 0.0814 - val_loss: 0.4736 - val_mse: 0.0786\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.2865 - mse: 0.0774 - val_loss: 0.1620 - val_mse: 0.0764\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.1154 - mse: 0.0764 - val_loss: 0.0881 - val_mse: 0.0760\n",
      "Epoch 5/10\n",
      "375/375 - 4s - loss: 0.0810 - mse: 0.0762 - val_loss: 0.0771 - val_mse: 0.0760\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0766 - mse: 0.0762 - val_loss: 0.0762 - val_mse: 0.0760\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0764 - mse: 0.0762 - val_loss: 0.0761 - val_mse: 0.0760\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0763 - mse: 0.0762 - val_loss: 0.0761 - val_mse: 0.0760\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0763 - mse: 0.0762 - val_loss: 0.0761 - val_mse: 0.0760\n",
      "Epoch 10/10\n",
      "375/375 - 3s - loss: 0.0764 - mse: 0.0762 - val_loss: 0.0762 - val_mse: 0.0760\n"
     ]
    }
   ],
   "source": [
    "l2_reg_dnn_dict={}\n",
    "for i in param_grid['l2_reg_dnn']:\n",
    "    model = WDL(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(2,2), l2_reg_linear=.1,\n",
    "            l2_reg_embedding=.001, l2_reg_dnn=i,  seed=1024,task='binary')\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    \n",
    "    #model prediction\n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "     #model evaluation RMSE, MAE,MSE\n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    \n",
    "    l2_reg_dnn_dict[i]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),3),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),3),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),3),\n",
    "      \"AUC\" : np.round(auc,3)}\n",
    "result['l2_reg_dnn']=l2_reg_dnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "false-lindsay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'RMSE': 0.264, 'MAE': 0.143, 'MSE': 0.07, 'AUC': 0.778},\n",
       " 0.2: {'RMSE': 0.276, 'MAE': 0.155, 'MSE': 0.076, 'AUC': 0.677},\n",
       " 2: {'RMSE': 0.276, 'MAE': 0.152, 'MSE': 0.076, 'AUC': 0.672},\n",
       " 4: {'RMSE': 0.276, 'MAE': 0.155, 'MSE': 0.076, 'AUC': 0.659}}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_dnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "premium-wildlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.264, 'MAE': 0.143, 'MSE': 0.07, 'AUC': 0.778}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_dnn_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-permission",
   "metadata": {},
   "source": [
    "### dnn_dropout â€“ float in [0,1), the probability we will drop out a given DNN coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "infrared-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 4s - loss: 0.0983 - mse: 0.0888 - val_loss: 0.0779 - val_mse: 0.0752\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0763 - mse: 0.0740 - val_loss: 0.0748 - val_mse: 0.0727\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0748 - mse: 0.0724 - val_loss: 0.0742 - val_mse: 0.0715\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0744 - mse: 0.0712 - val_loss: 0.0739 - val_mse: 0.0707\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0740 - mse: 0.0705 - val_loss: 0.0743 - val_mse: 0.0706\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0736 - mse: 0.0700 - val_loss: 0.0735 - val_mse: 0.0699\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0732 - mse: 0.0695 - val_loss: 0.0736 - val_mse: 0.0701\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0730 - mse: 0.0693 - val_loss: 0.0734 - val_mse: 0.0697\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0728 - mse: 0.0691 - val_loss: 0.0733 - val_mse: 0.0698\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0725 - mse: 0.0689 - val_loss: 0.0732 - val_mse: 0.0699\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0997 - mse: 0.0905 - val_loss: 0.0783 - val_mse: 0.0750\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0816 - mse: 0.0786 - val_loss: 0.0754 - val_mse: 0.0725\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0791 - mse: 0.0761 - val_loss: 0.0745 - val_mse: 0.0713\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0777 - mse: 0.0743 - val_loss: 0.0740 - val_mse: 0.0707\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0768 - mse: 0.0734 - val_loss: 0.0739 - val_mse: 0.0705\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0762 - mse: 0.0728 - val_loss: 0.0737 - val_mse: 0.0704\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0756 - mse: 0.0722 - val_loss: 0.0736 - val_mse: 0.0704\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0753 - mse: 0.0720 - val_loss: 0.0734 - val_mse: 0.0702\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0750 - mse: 0.0717 - val_loss: 0.0740 - val_mse: 0.0706\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0746 - mse: 0.0712 - val_loss: 0.0735 - val_mse: 0.0702\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1105 - mse: 0.0969 - val_loss: 0.0830 - val_mse: 0.0759\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0869 - mse: 0.0816 - val_loss: 0.0776 - val_mse: 0.0732\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0822 - mse: 0.0786 - val_loss: 0.0755 - val_mse: 0.0725\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0801 - mse: 0.0772 - val_loss: 0.0747 - val_mse: 0.0718\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0791 - mse: 0.0762 - val_loss: 0.0742 - val_mse: 0.0716\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0782 - mse: 0.0753 - val_loss: 0.0742 - val_mse: 0.0714\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0772 - mse: 0.0744 - val_loss: 0.0742 - val_mse: 0.0711\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0766 - mse: 0.0737 - val_loss: 0.0737 - val_mse: 0.0710\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0764 - mse: 0.0734 - val_loss: 0.0738 - val_mse: 0.0710\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0759 - mse: 0.0729 - val_loss: 0.0737 - val_mse: 0.0708\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1184 - mse: 0.1013 - val_loss: 0.0945 - val_mse: 0.0811\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0974 - mse: 0.0860 - val_loss: 0.0870 - val_mse: 0.0776\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0908 - mse: 0.0831 - val_loss: 0.0822 - val_mse: 0.0760\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0867 - mse: 0.0816 - val_loss: 0.0792 - val_mse: 0.0752\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0838 - mse: 0.0803 - val_loss: 0.0779 - val_mse: 0.0750\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0816 - mse: 0.0792 - val_loss: 0.0765 - val_mse: 0.0746\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0799 - mse: 0.0782 - val_loss: 0.0757 - val_mse: 0.0742\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0787 - mse: 0.0773 - val_loss: 0.0753 - val_mse: 0.0742\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0779 - mse: 0.0767 - val_loss: 0.0753 - val_mse: 0.0743\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0772 - mse: 0.0762 - val_loss: 0.0748 - val_mse: 0.0738\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1111 - mse: 0.0978 - val_loss: 0.0859 - val_mse: 0.0761\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0927 - mse: 0.0841 - val_loss: 0.0807 - val_mse: 0.0732\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0870 - mse: 0.0810 - val_loss: 0.0773 - val_mse: 0.0725\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0841 - mse: 0.0800 - val_loss: 0.0760 - val_mse: 0.0726\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0816 - mse: 0.0786 - val_loss: 0.0755 - val_mse: 0.0727\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0803 - mse: 0.0777 - val_loss: 0.0750 - val_mse: 0.0726\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0790 - mse: 0.0768 - val_loss: 0.0745 - val_mse: 0.0723\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0780 - mse: 0.0759 - val_loss: 0.0745 - val_mse: 0.0725\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0773 - mse: 0.0754 - val_loss: 0.0744 - val_mse: 0.0723\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0768 - mse: 0.0749 - val_loss: 0.0744 - val_mse: 0.0725\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1142 - mse: 0.0992 - val_loss: 0.0894 - val_mse: 0.0770\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0951 - mse: 0.0850 - val_loss: 0.0834 - val_mse: 0.0748\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0893 - mse: 0.0825 - val_loss: 0.0793 - val_mse: 0.0737\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0856 - mse: 0.0811 - val_loss: 0.0775 - val_mse: 0.0739\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0830 - mse: 0.0799 - val_loss: 0.0763 - val_mse: 0.0736\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0810 - mse: 0.0787 - val_loss: 0.0758 - val_mse: 0.0739\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0795 - mse: 0.0777 - val_loss: 0.0754 - val_mse: 0.0736\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0785 - mse: 0.0769 - val_loss: 0.0749 - val_mse: 0.0733\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0777 - mse: 0.0762 - val_loss: 0.0748 - val_mse: 0.0733\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0771 - mse: 0.0757 - val_loss: 0.0742 - val_mse: 0.0729\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1178 - mse: 0.1012 - val_loss: 0.0940 - val_mse: 0.0797\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0978 - mse: 0.0859 - val_loss: 0.0860 - val_mse: 0.0767\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0916 - mse: 0.0837 - val_loss: 0.0817 - val_mse: 0.0754\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0877 - mse: 0.0823 - val_loss: 0.0792 - val_mse: 0.0750\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0845 - mse: 0.0808 - val_loss: 0.0778 - val_mse: 0.0746\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0820 - mse: 0.0795 - val_loss: 0.0767 - val_mse: 0.0746\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0800 - mse: 0.0783 - val_loss: 0.0757 - val_mse: 0.0743\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0787 - mse: 0.0775 - val_loss: 0.0751 - val_mse: 0.0740\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0778 - mse: 0.0767 - val_loss: 0.0750 - val_mse: 0.0741\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0772 - mse: 0.0763 - val_loss: 0.0750 - val_mse: 0.0742\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1265 - mse: 0.1053 - val_loss: 0.1101 - val_mse: 0.0897\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.1044 - mse: 0.0878 - val_loss: 0.0945 - val_mse: 0.0813\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0967 - mse: 0.0856 - val_loss: 0.0898 - val_mse: 0.0804\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0915 - mse: 0.0837 - val_loss: 0.0857 - val_mse: 0.0792\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0872 - mse: 0.0818 - val_loss: 0.0827 - val_mse: 0.0783\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0839 - mse: 0.0803 - val_loss: 0.0804 - val_mse: 0.0776\n",
      "Epoch 7/10\n",
      "375/375 - 3s - loss: 0.0814 - mse: 0.0791 - val_loss: 0.0789 - val_mse: 0.0771\n",
      "Epoch 8/10\n",
      "375/375 - 3s - loss: 0.0797 - mse: 0.0782 - val_loss: 0.0778 - val_mse: 0.0767\n",
      "Epoch 9/10\n",
      "375/375 - 3s - loss: 0.0784 - mse: 0.0774 - val_loss: 0.0768 - val_mse: 0.0760\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0776 - mse: 0.0770 - val_loss: 0.0763 - val_mse: 0.0759\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1246 - mse: 0.1044 - val_loss: 0.1062 - val_mse: 0.0877\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.1044 - mse: 0.0881 - val_loss: 0.0979 - val_mse: 0.0840\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0977 - mse: 0.0858 - val_loss: 0.0918 - val_mse: 0.0816\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0921 - mse: 0.0837 - val_loss: 0.0873 - val_mse: 0.0805\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0874 - mse: 0.0818 - val_loss: 0.0838 - val_mse: 0.0792\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0841 - mse: 0.0803 - val_loss: 0.0813 - val_mse: 0.0784\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0815 - mse: 0.0791 - val_loss: 0.0794 - val_mse: 0.0777\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0796 - mse: 0.0781 - val_loss: 0.0781 - val_mse: 0.0769\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0784 - mse: 0.0775 - val_loss: 0.0773 - val_mse: 0.0766\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0776 - mse: 0.0770 - val_loss: 0.0767 - val_mse: 0.0762\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.1246 - mse: 0.1043 - val_loss: 0.1048 - val_mse: 0.0866\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.1043 - mse: 0.0882 - val_loss: 0.0975 - val_mse: 0.0836\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0979 - mse: 0.0859 - val_loss: 0.0919 - val_mse: 0.0817\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0922 - mse: 0.0838 - val_loss: 0.0875 - val_mse: 0.0808\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0876 - mse: 0.0819 - val_loss: 0.0842 - val_mse: 0.0797\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0841 - mse: 0.0804 - val_loss: 0.0815 - val_mse: 0.0786\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0815 - mse: 0.0791 - val_loss: 0.0795 - val_mse: 0.0777\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0797 - mse: 0.0782 - val_loss: 0.0783 - val_mse: 0.0773\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0784 - mse: 0.0775 - val_loss: 0.0775 - val_mse: 0.0767\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0776 - mse: 0.0770 - val_loss: 0.0769 - val_mse: 0.0765\n"
     ]
    }
   ],
   "source": [
    "dnn_dropout_dict={}\n",
    "for i in param_grid['dnn_dropout']:\n",
    "    model = WDL(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(2,2), l2_reg_linear=.1,\n",
    "            l2_reg_embedding=.001, l2_reg_dnn=0, seed=1024, dnn_dropout=i, dnn_activation='relu',task='binary')\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    \n",
    "    #model prediction \n",
    "    pred_result = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "    #model evaluation\n",
    "    auc = roc_auc_score(test[target].values, pred_result)\n",
    "    \n",
    "    dnn_dropout_dict[i]={\"RMSE\": np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),3),\n",
    "      \"MAE\" : np.round(mean_absolute_error(test[target].values, pred_result),3),\n",
    "      \"MSE\" : np.round(mean_squared_error(test[target].values, pred_result),3),\n",
    "      \"AUC\" : np.round(auc,3)}\n",
    "result['dnn_dropout']=dnn_dropout_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "subject-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: {'RMSE': 0.265, 'MAE': 0.144, 'MSE': 0.07, 'AUC': 0.777},\n",
       " 0.1: {'RMSE': 0.266, 'MAE': 0.136, 'MSE': 0.071, 'AUC': 0.776},\n",
       " 0.2: {'RMSE': 0.267, 'MAE': 0.134, 'MSE': 0.072, 'AUC': 0.763},\n",
       " 0.30000000000000004: {'RMSE': 0.272,\n",
       "  'MAE': 0.153,\n",
       "  'MSE': 0.074,\n",
       "  'AUC': 0.728},\n",
       " 0.4: {'RMSE': 0.27, 'MAE': 0.153, 'MSE': 0.073, 'AUC': 0.747},\n",
       " 0.5: {'RMSE': 0.271, 'MAE': 0.149, 'MSE': 0.073, 'AUC': 0.737},\n",
       " 0.6000000000000001: {'RMSE': 0.273, 'MAE': 0.161, 'MSE': 0.075, 'AUC': 0.709},\n",
       " 0.7000000000000001: {'RMSE': 0.276, 'MAE': 0.169, 'MSE': 0.076, 'AUC': 0.692},\n",
       " 0.8: {'RMSE': 0.277, 'MAE': 0.169, 'MSE': 0.077, 'AUC': 0.659},\n",
       " 0.9: {'RMSE': 0.277, 'MAE': 0.171, 'MSE': 0.077, 'AUC': 0.582}}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_dropout_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "prerequisite-federation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.265, 'MAE': 0.144, 'MSE': 0.07, 'AUC': 0.777}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_dropout_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-direction",
   "metadata": {},
   "source": [
    "## Model after all Hyper-parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "upper-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 - 3s - loss: 0.0952 - mse: 0.0867 - val_loss: 0.0775 - val_mse: 0.0752\n",
      "Epoch 2/10\n",
      "375/375 - 2s - loss: 0.0762 - mse: 0.0743 - val_loss: 0.0751 - val_mse: 0.0731\n",
      "Epoch 3/10\n",
      "375/375 - 2s - loss: 0.0750 - mse: 0.0729 - val_loss: 0.0744 - val_mse: 0.0722\n",
      "Epoch 4/10\n",
      "375/375 - 2s - loss: 0.0746 - mse: 0.0720 - val_loss: 0.0739 - val_mse: 0.0714\n",
      "Epoch 5/10\n",
      "375/375 - 2s - loss: 0.0742 - mse: 0.0713 - val_loss: 0.0739 - val_mse: 0.0707\n",
      "Epoch 6/10\n",
      "375/375 - 2s - loss: 0.0739 - mse: 0.0706 - val_loss: 0.0739 - val_mse: 0.0706\n",
      "Epoch 7/10\n",
      "375/375 - 2s - loss: 0.0737 - mse: 0.0702 - val_loss: 0.0735 - val_mse: 0.0701\n",
      "Epoch 8/10\n",
      "375/375 - 2s - loss: 0.0733 - mse: 0.0698 - val_loss: 0.0732 - val_mse: 0.0699\n",
      "Epoch 9/10\n",
      "375/375 - 2s - loss: 0.0731 - mse: 0.0696 - val_loss: 0.0733 - val_mse: 0.0699\n",
      "Epoch 10/10\n",
      "375/375 - 2s - loss: 0.0728 - mse: 0.0692 - val_loss: 0.0731 - val_mse: 0.0698\n"
     ]
    }
   ],
   "source": [
    "model = WDL(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(2,2), l2_reg_linear=.1,\n",
    "        l2_reg_embedding=0.001, l2_reg_dnn=0, dnn_dropout=0, seed=1024, task='binary')\n",
    "\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'])\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "improved-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "pred_result = model.predict(test_model_input, batch_size=256)\n",
    "auc = roc_auc_score(test[target].values, pred_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "nearby-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t0.260000\n",
      "MAE:\t0.140000\n",
      "MSE:\t0.070000\n",
      "AUC score:\t0.780000\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\\t%f\" % np.round(math.sqrt(mean_squared_error(test[target].values, pred_result)),2),\"MAE:\\t%f\" % np.round(mean_absolute_error(test[target].values, pred_result),2),\n",
    "      \"MSE:\\t%f\" % np.round(mean_squared_error(test[target].values, pred_result),2),\"AUC score:\\t%f\" % np.round(auc,2), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-plastic",
   "metadata": {},
   "source": [
    "# ROC Curves and AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "square-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    }
   ],
   "source": [
    "# fpr Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "# tpr Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "# thresholds Decreasing thresholds on the decision function used to compute fpr and tpr.\n",
    "# pos_label The label of the positive class. \n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test[target].values, pred_result, pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "provincial-composer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpr :  [0.00000000e+00 3.33333333e-05 2.33333333e-04 ... 9.99900000e-01\n",
      " 9.99966667e-01 1.00000000e+00]\n",
      "tpr :  [nan nan nan ... nan nan nan]\n",
      "thresholds [1.3706148  0.37061477 0.36990315 ... 0.00170422 0.00144324 0.00137275]\n"
     ]
    }
   ],
   "source": [
    "print(\"fpr : \", fpr)\n",
    "print(\"tpr : \",  tpr)\n",
    "print(\"thresholds\" , thresholds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "hungry-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.50\n",
      "Logistic: ROC AUC=0.78\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(pred_result))]\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = pred_result\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "#lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(test[target].values, ns_probs)\n",
    "lr_auc = roc_auc_score(test[target].values, lr_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.2f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.2f' % (lr_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(test[target].values, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(test[target].values, lr_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-silly",
   "metadata": {},
   "source": [
    "## Recommend Hotel for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "precise-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "hotel = list(df.drop_duplicates(subset='item_id', keep='first').item_id)\n",
    "names = list(df.drop_duplicates(subset='item_id', keep='first').item_id)\n",
    "\n",
    "for i in range(len(hotel)):\n",
    "    rows.append( dict({'name': names[i], 'item_id' : hotel[i], 'user_id' : 1048}))\n",
    "test_data = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "numerical-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_id 1048 recommended   hotel cluster:  45\n",
      "User_id 1048 recommended   hotel cluster:  17\n",
      "User_id 1048 recommended   hotel cluster:  40\n",
      "User_id 1048 recommended   hotel cluster:  11\n",
      "User_id 1048 recommended   hotel cluster:  98\n"
     ]
    }
   ],
   "source": [
    "for idx, (score, name) in enumerate(sorted(zip(pred_result, names), reverse=True)):\n",
    "    if idx >= 5:\n",
    "        break\n",
    " \n",
    "    print(\"User_id 1048 recommended \", \" hotel cluster: \", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-heath",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "https://arxiv.org/abs/1606.07792\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR\n",
    "\n",
    "https://deepctr-doc.readthedocs.io/en/v0.3.1/deepctr.models.wdl.html\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR/blob/ce140ffcc1057e8fb57622ae1732c39df32bc11e/docs/source/FAQ.md\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR/blob/db229dc31f0d4c79c0de2ece0bb919b35258d6b2/examples/run_regression_movielens.py\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR/blob/db229dc31f0d4c79c0de2ece0bb919b35258d6b2/examples/run_multivalue_movielens.py\n",
    "\n",
    "https://deepctr-doc.readthedocs.io/en/latest/Examples.html#classification-criteo\n",
    "\n",
    "https://deepctr-doc.readthedocs.io/en/latest/Quick-Start.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-jacob",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
